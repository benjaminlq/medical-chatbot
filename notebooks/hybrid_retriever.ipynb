{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tv1zxm8ILCBr",
        "outputId": "73da5b2e-95e5-4832-eb52-2c24943c6964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.18.0)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.18.0\n",
            "    Uninstalling transformers-4.18.0:\n",
            "      Successfully uninstalled transformers-4.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "splade 2.1 requires transformers==4.18.0, but you have transformers 4.33.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed transformers-4.33.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting git+https://github.com/naver/splade.git\n",
            "  Cloning https://github.com/naver/splade.git to /tmp/pip-req-build-gvr4h5hv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/naver/splade.git /tmp/pip-req-build-gvr4h5hv\n",
            "  Resolved https://github.com/naver/splade.git to commit 3781228d5f07e7a6ae14a479e469a715de79e976\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers==4.18.0 (from SPLADE==2.1)\n",
            "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "Requirement already satisfied: omegaconf==2.1.2 in /usr/local/lib/python3.10/dist-packages (from SPLADE==2.1) (2.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.2->SPLADE==2.1) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.1.2->SPLADE==2.1) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (2.31.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (0.0.53)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0->SPLADE==2.1) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0->SPLADE==2.1) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0->SPLADE==2.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0->SPLADE==2.1) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0->SPLADE==2.1) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0->SPLADE==2.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0->SPLADE==2.1) (1.3.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.33.1\n",
            "    Uninstalling transformers-4.33.1:\n",
            "      Successfully uninstalled transformers-4.33.1\n",
            "Successfully installed transformers-4.18.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --quiet langchain faiss-cpu tiktoken openai pinecone-client pinecone_text PyMuPDF\n",
        "!pip install --upgrade transformers\n",
        "!pip install git+https://github.com/naver/splade.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmjpfls-LNqe",
        "outputId": "cc7f230d-3c8c-426f-c1b4-3dda6b45d18e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/QUAN/Desktop/medical-chatbot\n",
            "Current Directory: /mnt/c/Users/QUAN/Desktop/medical-chatbot\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "\n",
        "# %cd /content/drive/MyDrive/LLM/qa_rag/ulcerative_colitis/\n",
        "\n",
        "import os, json\n",
        "from config import MAIN_DIR\n",
        "\n",
        "%cd ..\n",
        "print(\"Current Directory:\", MAIN_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EsTzrquqVFQ_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from splade.models.transformer_rep import Splade\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"./src\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4MGzTybLtgf",
        "outputId": "49ba9e0b-e94b-4e82-ed9d-62b5d8f1b9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of test cases: 30\n"
          ]
        }
      ],
      "source": [
        "with open(os.path.join(MAIN_DIR, \"data\", \"queries\", \"uc_all.txt\"), \"r\") as f:\n",
        "    test_cases = f.readlines()\n",
        "\n",
        "print(\"Total number of test cases:\", len(test_cases))\n",
        "\n",
        "with open(os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\"), \"r\") as f:\n",
        "    api_keys = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "722XfyM2K_Zj"
      },
      "source": [
        "# OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H1N5X6nuK_Zl"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.embeddings.base import Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4felXtbK_Zl",
        "outputId": "b99bb537-91dc-4f93-d378-8d8451ef6c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of test cases: 30\n",
            "Length of embeddings: 1536\n"
          ]
        }
      ],
      "source": [
        "EMB_DIR = os.path.join(MAIN_DIR, \"data\", \"emb_store\", \"uc\", \"faiss\", \"text-embedding-ada-002\")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_keys[\"OPENAI_API_KEY\"]\n",
        "\n",
        "with open(os.path.join(MAIN_DIR, \"data\", \"queries\", \"uc_all_emb.json\"), \"r\") as f:\n",
        "    test_cases_emb = json.load(f)\n",
        "\n",
        "test_cases = [(txt, emb) for txt, emb in zip(test_cases, test_cases_emb)]\n",
        "print(\"Number of test cases:\", len(test_cases))\n",
        "print(\"Length of embeddings:\", len(test_cases[0][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqgJtmVcK_Zm"
      },
      "outputs": [],
      "source": [
        "embedding_function = OpenAIEmbeddings().embed_query\n",
        "docsearch = FAISS.load_local(os.path.join(EMB_DIR, \"v8-add-tables_2500_500\"), OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLep-nUOK_Zm"
      },
      "outputs": [],
      "source": [
        "k = 10\n",
        "\n",
        "info = {\"question\": [], \"average_score\": [], \"min_score\": [], \"max_score\": []}\n",
        "\n",
        "for idx in range(10):\n",
        "    info[f\"Doc {idx+1} text\"] = []\n",
        "    info[f\"Doc {idx+1} score\"] = []\n",
        "\n",
        "for test_case in test_cases:\n",
        "    info[\"question\"].append(test_case[0])\n",
        "    relevant_docs_and_scores = docsearch.similarity_search_with_score_by_vector(test_case[1], k = k)\n",
        "    scores = [doc_and_score[1] for doc_and_score in relevant_docs_and_scores]\n",
        "    info[\"average_score\"].append(np.mean(scores))\n",
        "    info[\"min_score\"].append(np.min(scores))\n",
        "    info[\"max_score\"].append(np.max(scores))\n",
        "    for idx, doc_and_score in enumerate(relevant_docs_and_scores):\n",
        "        doc, score = doc_and_score\n",
        "        info[f\"Doc {idx+1} text\"].append(doc.page_content)\n",
        "        info[f\"Doc {idx+1} score\"].append(score)\n",
        "\n",
        "df = pd.DataFrame(info)\n",
        "save_folder = os.path.join(MAIN_DIR, \"artifacts\", \"similarity-search-analysis-text-embedding-ada-002\")\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "df.to_csv(os.path.join(save_folder, \"summary.csv\"), header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZki0DX-K_Zn"
      },
      "outputs": [],
      "source": [
        "docstores = [\"v6-add-tables_750_100\", \"v7-add-tables_1000_200\", \"v8-add-tables_2500_500\", \"v9-add-tables_1500_300\"]\n",
        "\n",
        "info = {\"question\": [test_case[0] for test_case in test_cases]}\n",
        "\n",
        "for docstore in docstores:\n",
        "    docsearch = FAISS.load_local(os.path.join(EMB_DIR, docstore),OpenAIEmbeddings())\n",
        "    chunk_size = docstore.split(\"_\")[-2]\n",
        "    info[f\"{chunk_size}_average_score\"] = []\n",
        "    info[f\"{chunk_size}_min_score\"] = []\n",
        "    info[f\"{chunk_size}_max_score\"] = []\n",
        "\n",
        "    for test_case in test_cases:\n",
        "        relevant_docs_and_scores = docsearch.similarity_search_with_score_by_vector(test_case[1], k = k)\n",
        "        scores = [doc_and_score[1] for doc_and_score in relevant_docs_and_scores]\n",
        "        info[f\"{chunk_size}_average_score\"].append(np.mean(scores))\n",
        "        info[f\"{chunk_size}_min_score\"].append(np.min(scores))\n",
        "        info[f\"{chunk_size}_max_score\"].append(np.max(scores))\n",
        "\n",
        "df_scores = pd.DataFrame(info)\n",
        "save_folder = os.path.join(MAIN_DIR, \"artifacts\", \"similarity-search-analysis-text-embedding-ada-002\")\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "df_scores.to_csv(os.path.join(save_folder, \"compare_database.csv\"), header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qowmhMsOMKAo"
      },
      "source": [
        "# SPLADE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp3zUBSoCRZ5",
        "outputId": "036a5d48-cd89-42b6-9ef5-a83b602febab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using CUDA\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rA4wWIvMIY9",
        "outputId": "ba8fbf43-3a69-4510-cd13-a282db163871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40 year old male with newly diagnosed moderate UC and articular extraintestinal manifestations\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = 'naver/splade-cocondenser-ensembledistil'\n",
        "model_path = os.path.join(MAIN_DIR, \"pretrained\", \"splade-cocondenser-ensembledistil\")\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Cannot find model at path {model_path}. Download new files.\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "    model.save_pretrained(model_path)\n",
        "    tokenizer.save_pretrained(model_path)\n",
        "\n",
        "sample_testcase = test_cases[0]\n",
        "print(sample_testcase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvIjUs9aHYlk",
        "outputId": "85c86074-18b0-4a91-c217-944a8fd4ea39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  2871,  2095,  2214,  3287,  2007,  4397, 11441,  8777, 15384,\n",
            "          1998,  2396, 21412,  4469, 18447, 19126, 24491,  2015,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "splade_model = Splade(model_type_or_dir = model_path, agg=\"max\")\n",
        "splade_model.to(device)\n",
        "splade_model.eval()\n",
        "tokenizer = splade_model.transformer_rep.tokenizer\n",
        "\n",
        "with torch.no_grad():\n",
        "    tokens = tokenizer(sample_testcase, return_tensors = \"pt\")\n",
        "    print(tokens)\n",
        "    tokens = tokens.to(device)\n",
        "    sparse_emb = splade_model(d_kwargs = tokens)\n",
        "    vec = sparse_emb[\"d_rep\"].cpu()\n",
        "\n",
        "vec = vec[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5Ushpl1uaLR",
        "outputId": "e4c4d87d-7191-439a-c8bd-2242ff555fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of non zero tokens: 51\n",
            "\n"
          ]
        }
      ],
      "source": [
        "non_zero_idx = vec.nonzero().squeeze().tolist()\n",
        "print(\"Number of non zero tokens: {}\\n\".format(len(non_zero_idx)))\n",
        "\n",
        "non_zero_weights = vec[non_zero_idx].tolist()\n",
        "sparse_dict = dict(zip(non_zero_idx, non_zero_weights))\n",
        "\n",
        "idx2token = {idx: token for token, idx in tokenizer.get_vocab().items()}\n",
        "\n",
        "sparse_dict_tokens = {idx2token[idx]:round(weight,3) for idx, weight in sparse_dict.items()}\n",
        "\n",
        "sparse_dict_tokens = {\n",
        "    k: v for k, v in\n",
        "    sorted(sparse_dict_tokens.items(), key=lambda item: item[1], reverse=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD2ocHza1fTV"
      },
      "source": [
        "# Hybrid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciN6yustKAC0"
      },
      "source": [
        "## SPLADE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0E-8oZKToNgu"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from splade.models.transformer_rep import Splade\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "apOFDnCH1d7o"
      },
      "outputs": [],
      "source": [
        "index_name = \"uc-hybrid-search\"\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=api_keys[\"PINECONE_API_SPLADE\"][\"KEY\"],\n",
        "    environment=api_keys[\"PINECONE_API_SPLADE\"][\"ENV\"]\n",
        "    )\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        name=index_name, dimension=1536, metric=\"dotproduct\", pod_type=\"s1\", metadata_config={\"indexed\": []},\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HpI36BKfpKRh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/lequan2902/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from pinecone_text.sparse import SparseVector\n",
        "from pinecone_text.sparse.base_sparse_encoder import BaseSparseEncoder\n",
        "from typing import Union, List, Literal, Optional\n",
        "\n",
        "class SpladeEncoder(BaseSparseEncoder):\n",
        "\n",
        "    \"\"\"\n",
        "    SPLADE sparse vector encoder.\n",
        "    Currently only supports inference with  naver/splade-cocondenser-ensembledistil\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path: Optional[str] = None, max_seq_length: int = 256,\n",
        "                 agg: Literal[\"max\", \"sum\"] = \"max\", device: str = \"cpu\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_seq_length: Maximum sequence length for the model. Must be between 1 and 512.\n",
        "            device: Device to use for inference.\n",
        "\n",
        "        Example:\n",
        "\n",
        "            ```python\n",
        "            from pinecone_text.sparse import SPLADE\n",
        "\n",
        "            splade = SPLADE()\n",
        "\n",
        "            splade.encode_documents(\"this is a document\") # [{\"indices\": [102, 18, 12, ...], \"values\": [0.21, 0.38, 0.15, ...]}, ...]\n",
        "            ```\n",
        "        \"\"\"\n",
        "        if not 0 < max_seq_length <= 512:\n",
        "            raise ValueError(\"max_seq_length must be between 1 and 512\")\n",
        "\n",
        "        model = model_path if model_path else \"naver/splade-cocondenser-ensembledistil\"\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "        self.model = AutoModelForMaskedLM.from_pretrained(model).to(device)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.agg_fn = getattr(torch, agg)\n",
        "        self.device = device\n",
        "\n",
        "    def encode_documents(\n",
        "        self, texts: Union[str, List[str]]\n",
        "    ) -> Union[SparseVector, List[SparseVector]]:\n",
        "        \"\"\"\n",
        "        encode documents to a sparse vector (for upsert to pinecone)\n",
        "\n",
        "        Args:\n",
        "            texts: a single or list of documents to encode as a string\n",
        "        \"\"\"\n",
        "        return self._encode(texts)\n",
        "\n",
        "    def encode_queries(\n",
        "        self, texts: Union[str, List[str]]\n",
        "    ) -> Union[SparseVector, List[SparseVector]]:\n",
        "        \"\"\"\n",
        "        encode queries to a sparse vector (for upsert to pinecone)\n",
        "\n",
        "        Args:\n",
        "            texts: a single or list of queries to encode as a string\n",
        "        \"\"\"\n",
        "        return self._encode(texts)\n",
        "\n",
        "    def _encode(\n",
        "        self, texts: Union[str, List[str]]\n",
        "    ) -> Union[SparseVector, List[SparseVector]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts: single or list of texts to encode.\n",
        "\n",
        "        Returns a list of Splade sparse vectors, one for each input text.\n",
        "        \"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_seq_length,\n",
        "        ).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(**inputs).logits\n",
        "\n",
        "        inter = torch.log1p(torch.relu(logits))\n",
        "        token_max = self.agg_fn(inter, dim=1)\n",
        "\n",
        "        nz_tokens_i, nz_tokens_j = torch.where(token_max.values > 0)\n",
        "\n",
        "        output = []\n",
        "        for i in range(token_max.values.shape[0]):\n",
        "            nz_tokens = nz_tokens_j[nz_tokens_i == i]\n",
        "            nz_weights = token_max.values[i, nz_tokens]\n",
        "            output.append(\n",
        "                {\"indices\": nz_tokens.tolist(), \"values\": nz_weights.tolist()}\n",
        "            )\n",
        "\n",
        "        return output[0] if isinstance(texts, str) else output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ECOxs5GByYPZ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import PineconeHybridSearchRetriever\n",
        "from utils import convert_csv_to_documents, load_documents\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "splade_encoder = SpladeEncoder(model_path = model_path, max_seq_length = 512, agg = \"max\", device = device)\n",
        "embeddings = OpenAIEmbeddings(openai_api_key = api_keys[\"OPENAI_API_KEY\"])\n",
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIm_j-1aEe5L",
        "outputId": "ba26a472-cf55-431c-8be2-c474e439448c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading documents from /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 86 documents from /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc\n",
            "Split into 443 chunks of text (max. 1000 characters each)\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "source_directory = os.path.join(MAIN_DIR, \"data\", \"document_store\", \"uc\")\n",
        "additional_docs = os.path.join(MAIN_DIR, \"data\", \"additional_docs.json\")\n",
        "exclude_pages = {\n",
        "    \"agrawal.pdf\": [13, 14, 15, 16, 17, 18],\n",
        "    \"PIIS1542356520300446.pdf\": [12, 13, 14, 15, 16, 17, 18],\n",
        "    \"gutjnl-2021-326390R2 CLEAN.pdf\": [0, 2, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45],\n",
        "    \"otad009.pdf\": [15, 16],\n",
        "    \"1-s2.0-S2468125321003770-main.pdf\": [9],\n",
        "    \"juillerat 2022.pdf\": [6, 7, 8],\n",
        "}\n",
        "\n",
        "chunk_size = 1000\n",
        "chunk_overlap = 200\n",
        "\n",
        "print(f\"Loading documents from {source_directory}\")\n",
        "\n",
        "documents = load_documents(source_directory, exclude_pages=exclude_pages)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents from {source_directory}\")\n",
        "print(f\"Split into {len(texts)} chunks of text (max. {chunk_size} characters each)\")\n",
        "\n",
        "with open(additional_docs, \"r\") as f:\n",
        "    add_doc_infos = json.load(f)\n",
        "for add_doc_info in add_doc_infos:\n",
        "    texts.extend(convert_csv_to_documents(add_doc_info, concatenate_rows=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1fcf54a9bd134c4cbb9cb60dbcdcd825",
            "a6ee9a1add0d4d65a5b7eeaa784d4420",
            "405357a01b2e46b8b4a3231f23f64b10",
            "b210360fdcac4041ae303d01a94e09c8",
            "c4a01d5b540942dbbb6734cccae2ef47",
            "dff040c5ef9046e2adfbc3eae7970c63",
            "1e73b8941e414bfdbd0b2f0a729fdc81",
            "1021e44ed6e244508cab515aba54d677",
            "2719d7bb660c45128b56b5482a88d989",
            "27365580e2f24094a14e839b0cd12f78",
            "5927a0fb9c6f4a6f95f3e605d88ee3ec"
          ]
        },
        "id": "dtBHMkGRJnqH",
        "outputId": "a75f21de-d16c-451b-c56a-48c5db00e1dd"
      },
      "outputs": [],
      "source": [
        "page_contents = [text.page_content for text in texts]\n",
        "metadatas = [text.metadata for text in texts]\n",
        "\n",
        "retriever = PineconeHybridSearchRetriever(\n",
        "    embeddings=embeddings,\n",
        "    sparse_encoder=splade_encoder,\n",
        "    index = index,\n",
        "    top_k = 10,\n",
        "    alpha = 0.5\n",
        "    )\n",
        "\n",
        "## retriever.add_texts(texts=page_contents, metadatas=metadatas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ds7BprGSMbRH"
      },
      "outputs": [],
      "source": [
        "df_list = []\n",
        "k = 10\n",
        "\n",
        "for alpha in range(11):\n",
        "    retriever = PineconeHybridSearchRetriever(\n",
        "        embeddings=embeddings,\n",
        "        sparse_encoder=splade_encoder,\n",
        "        index=index,\n",
        "        top_k=k,\n",
        "        alpha=alpha / 10\n",
        "        )\n",
        "\n",
        "    answer_dict = {\"test_case\": test_cases}\n",
        "    for idx in range(k):\n",
        "        answer_dict[f\"doc{idx+1}\"] = []\n",
        "\n",
        "    for test_case in test_cases:\n",
        "        docs = retriever.get_relevant_documents(test_case)\n",
        "        for idx in range(k):\n",
        "            answer_dict[f\"doc{idx+1}\"].append(docs[idx].page_content)\n",
        "\n",
        "    df_list.append(pd.DataFrame(answer_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJU_nvuJ6XFT"
      },
      "outputs": [],
      "source": [
        "with pd.ExcelWriter(os.path.join(MAIN_DIR, \"log\", \"retrieval_analysis.xlsx\")) as writer:\n",
        "    for idx, df in enumerate(df_list):\n",
        "        df.to_excel(writer, sheet_name=f'alpha={idx/10}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2j9rlmz8Poj"
      },
      "outputs": [],
      "source": [
        "for idx, df in enumerate(df_list):\n",
        "    df[\"case_no\"] = list(range(1,31))\n",
        "    df[\"alpha\"] = idx/10\n",
        "\n",
        "combined_df = pd.concat(df_list)\n",
        "combined_df = combined_df.sort_values(\"case_no\")\n",
        "combined_df.to_csv(os.path.join(MAIN_DIR, \"log\", \"combined_retrieval_analysis.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFLp5J9hJ8fe"
      },
      "source": [
        "## BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dik-H2e87ZA"
      },
      "outputs": [],
      "source": [
        "index_name_bm25 = \"uc-hybrid-search-bm25\"\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=api_keys[\"PINECONE_API2\"][\"KEY\"],\n",
        "    environment=api_keys[\"PINECONE_API2\"][\"ENV\"]\n",
        "    )\n",
        "\n",
        "if index_name_bm25 not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        name=index_name_bm25, dimension=1536, metric=\"dotproduct\", pod_type=\"s1\", metadata_config={\"indexed\": []},\n",
        "    )\n",
        "\n",
        "index_bm25 = pinecone.Index(index_name_bm25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a831ceb0cb0d4754aba8298beb972633",
            "bcca1c3ecc36450aa5e49e73b8b660ba",
            "3a9bab6f1f9f4e2dbd29f396fda9dfcd",
            "631d0c602cf141b99b656fd05bb2fd7e",
            "3ce9686ce67946ad936ee9508fe41562",
            "5bf06a74e09347fb83e24fa84876c7f1",
            "23e3db75e0b947f59bce3de3e2ee4619",
            "797f216bd504470a819aec47481058a3",
            "d326ccfc90b64595a09b82e0f3e1770e",
            "f3241f149f204f0f9bb914dcf6fe4600",
            "c635589a878542a8ae65ce85f1645848"
          ]
        },
        "id": "gv3lKd7tM5F_",
        "outputId": "aed5cb31-f3e6-4834-fd2f-19dc2cc9af2d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a831ceb0cb0d4754aba8298beb972633",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/446 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pinecone_text.sparse import BM25Encoder\n",
        "\n",
        "bm25_encoder = BM25Encoder().default()\n",
        "\n",
        "# fit tf-idf values on your corpus\n",
        "bm25_encoder.fit(page_contents)\n",
        "\n",
        "# store the values to a json file\n",
        "artifact_dir = os.path.join(MAIN_DIR, \"artifacts\")\n",
        "if not os.path.exists(artifact_dir):\n",
        "    os.makedirs(artifact_dir, exist_ok = True)\n",
        "bm25_encoder.dump(os.path.join(artifact_dir, \"bm25_values.json\"))\n",
        "\n",
        "# load to your BM25Encoder object\n",
        "bm25_encoder = BM25Encoder().load(os.path.join(artifact_dir, \"bm25_values.json\"))\n",
        "\n",
        "bm25_retriever = PineconeHybridSearchRetriever(\n",
        "    embeddings=embeddings, sparse_encoder=bm25_encoder,\n",
        "    index=index_bm25, top_k = 10, alpha = 0.5\n",
        ")\n",
        "\n",
        "# bm25_retriever.add_texts(texts=page_contents, metadatas=metadatas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7tvSi_yQ_Do"
      },
      "outputs": [],
      "source": [
        "df_list = []\n",
        "k = 10\n",
        "\n",
        "for alpha in range(11):\n",
        "\n",
        "    bm25_retriever = PineconeHybridSearchRetriever(\n",
        "        embeddings=embeddings, sparse_encoder=bm25_encoder,\n",
        "        index=index_bm25, top_k=k, alpha=alpha/10\n",
        "    )\n",
        "\n",
        "    answer_dict = {\"test_case\": test_cases}\n",
        "    for idx in range(k):\n",
        "        answer_dict[f\"doc{idx+1}\"] = []\n",
        "\n",
        "    for test_case in test_cases:\n",
        "        docs = bm25_retriever.get_relevant_documents(test_case)\n",
        "        for idx in range(k):\n",
        "            answer_dict[f\"doc{idx+1}\"].append(docs[idx].page_content)\n",
        "\n",
        "    df_list.append(pd.DataFrame(answer_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPC2p3CNTs3g"
      },
      "outputs": [],
      "source": [
        "for idx, df in enumerate(df_list):\n",
        "    df[\"case_no\"] = list(range(1,31))\n",
        "    df[\"alpha\"] = idx/10\n",
        "\n",
        "combined_df = pd.concat(df_list)\n",
        "combined_df = combined_df.sort_values(\"case_no\")\n",
        "combined_df.to_csv(os.path.join(MAIN_DIR, \"log\", \"combined_retrieval_analysis_bm25.csv\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "722XfyM2K_Zj"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1021e44ed6e244508cab515aba54d677": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e73b8941e414bfdbd0b2f0a729fdc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fcf54a9bd134c4cbb9cb60dbcdcd825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6ee9a1add0d4d65a5b7eeaa784d4420",
              "IPY_MODEL_405357a01b2e46b8b4a3231f23f64b10",
              "IPY_MODEL_b210360fdcac4041ae303d01a94e09c8"
            ],
            "layout": "IPY_MODEL_c4a01d5b540942dbbb6734cccae2ef47"
          }
        },
        "23e3db75e0b947f59bce3de3e2ee4619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2719d7bb660c45128b56b5482a88d989": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27365580e2f24094a14e839b0cd12f78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9bab6f1f9f4e2dbd29f396fda9dfcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_797f216bd504470a819aec47481058a3",
            "max": 446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d326ccfc90b64595a09b82e0f3e1770e",
            "value": 446
          }
        },
        "3ce9686ce67946ad936ee9508fe41562": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405357a01b2e46b8b4a3231f23f64b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1021e44ed6e244508cab515aba54d677",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2719d7bb660c45128b56b5482a88d989",
            "value": 14
          }
        },
        "5927a0fb9c6f4a6f95f3e605d88ee3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bf06a74e09347fb83e24fa84876c7f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631d0c602cf141b99b656fd05bb2fd7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3241f149f204f0f9bb914dcf6fe4600",
            "placeholder": "​",
            "style": "IPY_MODEL_c635589a878542a8ae65ce85f1645848",
            "value": " 446/446 [00:01&lt;00:00, 267.57it/s]"
          }
        },
        "797f216bd504470a819aec47481058a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ee9a1add0d4d65a5b7eeaa784d4420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dff040c5ef9046e2adfbc3eae7970c63",
            "placeholder": "​",
            "style": "IPY_MODEL_1e73b8941e414bfdbd0b2f0a729fdc81",
            "value": "100%"
          }
        },
        "a831ceb0cb0d4754aba8298beb972633": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcca1c3ecc36450aa5e49e73b8b660ba",
              "IPY_MODEL_3a9bab6f1f9f4e2dbd29f396fda9dfcd",
              "IPY_MODEL_631d0c602cf141b99b656fd05bb2fd7e"
            ],
            "layout": "IPY_MODEL_3ce9686ce67946ad936ee9508fe41562"
          }
        },
        "b210360fdcac4041ae303d01a94e09c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27365580e2f24094a14e839b0cd12f78",
            "placeholder": "​",
            "style": "IPY_MODEL_5927a0fb9c6f4a6f95f3e605d88ee3ec",
            "value": " 14/14 [00:41&lt;00:00,  2.78s/it]"
          }
        },
        "bcca1c3ecc36450aa5e49e73b8b660ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf06a74e09347fb83e24fa84876c7f1",
            "placeholder": "​",
            "style": "IPY_MODEL_23e3db75e0b947f59bce3de3e2ee4619",
            "value": "100%"
          }
        },
        "c4a01d5b540942dbbb6734cccae2ef47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c635589a878542a8ae65ce85f1645848": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d326ccfc90b64595a09b82e0f3e1770e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dff040c5ef9046e2adfbc3eae7970c63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3241f149f204f0f9bb914dcf6fe4600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
