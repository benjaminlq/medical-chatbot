{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Xobu8QB8mu_l"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_vzyCRHF3Xn",
        "outputId": "8d3af069-413e-47d3-c178-039a969ad822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain openai faiss-cpu tiktoken pypdf PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G80rr2ZHP7d",
        "outputId": "25ff0a08-071b-4987-8876-968e9113649c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/LLM/ulcerative_colitis\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "%cd drive/MyDrive/LLM/ulcerative_colitis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nGWwk_exH6Op"
      },
      "outputs": [],
      "source": [
        "import os, sys, json, logging\n",
        "import os.path as osp\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "from typing import Union, Sequence, Dict, Callable, List, Optional\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from pprint import pprint\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import display, Markdown\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "from langchain.docstore.document import Document\n",
        "from chromadb.config import Settings\n",
        "\n",
        "from langchain import OpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import VectorStore, FAISS, Chroma, Pinecone\n",
        "import pinecone\n",
        "from langchain.document_loaders.pdf import PyMuPDFLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
        "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders.image import UnstructuredImageLoader\n",
        "\n",
        "from config import MAIN_DIR, DATA_DIR, EMBSTORE_DIR, ARTIFACT_DIR, DOCUMENT_SOURCE\n",
        "\n",
        "from shutil import rmtree\n",
        "from utils import load_single_document, load_documents\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l-VsrU--JBBK"
      },
      "outputs": [],
      "source": [
        "PROJECT = \"uc\"\n",
        "\n",
        "with open(osp.join(MAIN_DIR, \"auth\", \"api_keys.json\"), \"r\") as f:\n",
        "    keys = json.load(f)\n",
        "\n",
        "OPENAI_KEY = keys[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "piuTlxLNJTVC"
      },
      "outputs": [],
      "source": [
        "LOGGER = logging.getLogger()\n",
        "\n",
        "log_path = os.path.join(MAIN_DIR, \"log\", \"logfile.txt\")\n",
        "file_handler = logging.FileHandler(\n",
        "    filename=log_path)\n",
        "\n",
        "formatter = logging.Formatter(\"%(asctime)s:%(levelname)s: %(message)s\")\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "LOGGER.setLevel(logging.INFO)\n",
        "LOGGER.addHandler(file_handler)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Uslox4t9d8"
      },
      "source": [
        "# User-defined Functions (UDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "akNXqtFmt88J"
      },
      "outputs": [],
      "source": [
        "def convert_csv_to_documents(table_info: Dict, concatenate_rows: bool = True) -> List[Document]:\n",
        "    \"\"\"Convert a dictionary containing table information into list of Documents\n",
        "\n",
        "    Args:\n",
        "        table_info (Dict): Dictionary containing .csv table information\n",
        "\n",
        "    Returns:\n",
        "        List[Document]: List of rows inside the table\n",
        "    \"\"\"\n",
        "    assert table_info[\"mode\"] == \"table\" and table_info[\"filename\"].endswith(\".csv\")\n",
        "    rows = load_single_document(os.path.join(MAIN_DIR, table_info[\"filename\"]))\n",
        "    documents = []\n",
        "    table_content = table_info[\"description\"] + \"\\n\\n\"\n",
        "    for row in rows:\n",
        "        if concatenate_rows:\n",
        "            table_content += row.page_content + \"\\n\\n\"\n",
        "            table_doc = Document(\n",
        "                page_content=table_content,\n",
        "                metadata=table_info[\"metadata\"]\n",
        "            )\n",
        "        else:\n",
        "            row_no = row.metadata[\"row\"]\n",
        "            metadata = {k: v for k, v in table_info[\"metadata\"].items()}\n",
        "            metadata[\"row\"] = row_no\n",
        "            metadata[\"modal\"] = table_info[\"mode\"]\n",
        "            row.page_content = table_info[\"description\"] + \":\" + row.page_content\n",
        "            row.metadata = metadata\n",
        "            documents.append(row)\n",
        "            \n",
        "    if concatenate_rows:\n",
        "        documents.append(table_doc)\n",
        "    \n",
        "    return documents\n",
        "\n",
        "\n",
        "def convert_json_to_documents(json_info: Dict) -> List[Document]:\n",
        "    \"\"\"Convert a dictionary containing json information into list of Documents\n",
        "\n",
        "    Args:\n",
        "        table_info (Dict): Dictionary containing .json table information\n",
        "\n",
        "    Returns:\n",
        "        List[Document]: List of Documents\n",
        "    \"\"\"\n",
        "    return []\n",
        "\n",
        "\n",
        "def generate_vectorstore(\n",
        "    embeddings: Callable,\n",
        "    source_directory: Optional[str] = None,\n",
        "    output_directory: str = \"./vectorstore\",\n",
        "    emb_store_type: str = \"faiss\",\n",
        "    chunk_size: int = 1000,\n",
        "    chunk_overlap: int = 250,\n",
        "    exclude_pages: Optional[Dict] = None,\n",
        "    pinecone_idx_name: Optional[str] = None,\n",
        "    additional_docs: Optional[List] = None,\n",
        "    key_path: Optional[str] = os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\"),\n",
        ") -> VectorStore:\n",
        "    \"\"\"Generate New Vector Index Database\n",
        "\n",
        "    Args:\n",
        "        source_directory (str): Directory contains source documents\n",
        "        embeddings (Callable): Function to convert text to vector embeddings\n",
        "        output_directory (str, optional): Output directory of vector index database. Defaults to \"./vectorstore\".\n",
        "        emb_store_type (str, optional): Type of vector index database. Defaults to \"faiss\".\n",
        "        chunk_size (int, optional): Maximum size of text chunks (characters) after split. Defaults to 1000.\n",
        "        chunk_overlap (int, optional): Maximum overlapping window between text chunks. Defaults to 250.\n",
        "        exclude_pages (Optional[Dict], optional): Dictionary of pages to be excluded from documents. Defaults to None.\n",
        "        pinecone_idx_name (Optional[str], optional): Name of pinecone index to be created or loaded. Defaults to None.\n",
        "        additional_docs (Optional[str], optional): Additional Tables, Images or Json to be added to doc list. Defaults to None.\n",
        "        key_path (Optional[str], optional): Path to file containing API info.\n",
        "            Defaults to os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\").\n",
        "\n",
        "    Returns:\n",
        "        Vectorstore: Vector Database\n",
        "    \"\"\"\n",
        "\n",
        "    if os.path.exists(output_directory):\n",
        "        rmtree(output_directory)\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    if source_directory:\n",
        "        LOGGER.info(f\"Loading documents from {source_directory}\")\n",
        "\n",
        "        documents = load_documents(source_directory, exclude_pages=exclude_pages)\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        "        )\n",
        "        texts = text_splitter.split_documents(documents)\n",
        "\n",
        "        LOGGER.info(f\"Loaded {len(documents)} documents from {source_directory}\")\n",
        "        LOGGER.info(\n",
        "            f\"Split into {len(texts)} chunks of text (max. {chunk_size} characters each)\"\n",
        "        )\n",
        "    else:\n",
        "        texts = []\n",
        "\n",
        "    if additional_docs:\n",
        "        texts.extend(additional_docs)\n",
        "\n",
        "    LOGGER.info(\n",
        "        f\"Total number of text chunks to create vector index store: {len(texts)}\"\n",
        "    )\n",
        "\n",
        "    if emb_store_type == \"chroma\":\n",
        "        chroma_settings = Settings(\n",
        "            chroma_db_impl=\"duckdb+parquet\",\n",
        "            persist_directory=output_directory,\n",
        "            anonymized_telemetry=False,\n",
        "        )\n",
        "        db = Chroma.from_documents(\n",
        "            texts,\n",
        "            embeddings,\n",
        "            persist_directory=output_directory,\n",
        "            client_settings=chroma_settings,\n",
        "        )\n",
        "        db.persist()\n",
        "\n",
        "    elif emb_store_type == \"faiss\":\n",
        "        db = FAISS.from_documents(texts, embedding=embeddings)\n",
        "        db.save_local(output_directory)\n",
        "        assert \"index.faiss\" in os.listdir(\n",
        "            output_directory\n",
        "        ) and \"index.pkl\" in os.listdir(output_directory)\n",
        "\n",
        "    elif emb_store_type == \"pinecone\":\n",
        "        with open(key_path, \"r\") as f:\n",
        "            keys = json.loads(f)\n",
        "        PINECONE_API_KEY = keys[\"PINECONE_API\"][\"KEY\"]\n",
        "        PINECONE_ENV = keys[\"PINECONE_API\"][\"ENV\"]\n",
        "\n",
        "        pinecone.init(\n",
        "            api_key=PINECONE_API_KEY,\n",
        "            environment=PINECONE_ENV,\n",
        "        )\n",
        "\n",
        "        if not pinecone_idx_name:\n",
        "            pinecone_idx_name = \"index_{}\".format(\n",
        "                datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "            )\n",
        "\n",
        "        if pinecone_idx_name not in pinecone.list_indexes():\n",
        "            db = Pinecone.from_documents(\n",
        "                texts, embedding=embeddings, index_name=pinecone_idx_name\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            db = Pinecone.from_existing_index(pinecone_idx_name, embeddings)\n",
        "            db.add_documents(texts)\n",
        "\n",
        "    LOGGER.info(\n",
        "        f\"Successfully created {emb_store_type} vectorstore at {output_directory}\"\n",
        "    )\n",
        "\n",
        "    return db"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BP89lkLGsmKF"
      },
      "source": [
        "# Experiment Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OfcdafLxXEQx"
      },
      "outputs": [],
      "source": [
        "class DrugOutput(BaseModel):\n",
        "    drug_name: str = Field(description = \"Name of the drug\")\n",
        "    advantages: str = Field(description = \"Advantages of the drug \")\n",
        "    disadvantages: str = Field(description = \"Disadvantages of the drug\")\n",
        "\n",
        "class Experiment:\n",
        "    \"\"\"Experiment Module\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        prompt_template: Union[PromptTemplate, ChatPromptTemplate],\n",
        "        vector_store: str,\n",
        "        llm_type: str = \"gpt-3.5-turbo\",\n",
        "        emb: str = \"text-embedding-ada-002\",\n",
        "        keys_json: str = osp.join(MAIN_DIR, \"auth\", \"api_keys.json\"),\n",
        "        temperature: float = 0,\n",
        "        max_tokens: int = 512,\n",
        "        gt: Optional[str] = None,\n",
        "        verbose: bool = False,\n",
        "    ):\n",
        "        \"\"\"Initiate Instance for an experiment run\n",
        "\n",
        "        Args:\n",
        "            prompt_template (Union[PromptTemplate, ChatPromptTemplate]): Prompt to be feed to LLM\n",
        "            vector_store (str): Path to Vector Index Database\n",
        "            llm_type (str, optional): Type of LLM Model. Defaults to \"gpt-3.5-turbo\".\n",
        "            emb (str, optional): Type of Embedding Model. Defaults to \"text-embedding-ada-002\".\n",
        "            keys_json (str, optional): Path to API Keys. Defaults to osp.join(MAIN_DIR, \"auth\", \"api_keys.json\").\n",
        "            temperature (float, optional): Temperature Settings for LLM model. Lower temperature makes LLM more deterministic\n",
        "                while higher temperature makes LLM more random. Defaults to 0.\n",
        "            max_tokens (int, optional): Max_Tokens Settings for LLM model. Defaults to 512.\n",
        "            gt (Optional[str], optional): Path to Ground Truth file. Defaults to None.\n",
        "            verbose (bool, optional): Verbose Setting. Defaults to False.\n",
        "        \"\"\"\n",
        "\n",
        "        self.llm_type = llm_type.lower()\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "        with open(keys_json, \"r\") as f:\n",
        "            keys = json.load(f)\n",
        "\n",
        "        self.openai_key = (\n",
        "            keys[\"OPENAI_API_KEY_FOR_GPT4\"]\n",
        "            if self.llm_type == \"gpt-4\"\n",
        "            else keys[\"OPENAI_API_KEY\"]\n",
        "        )\n",
        "\n",
        "        if isinstance(prompt_template, ChatPromptTemplate):\n",
        "            self.llm = ChatOpenAI(\n",
        "                model_name=self.llm_type,\n",
        "                temperature=self.temperature,\n",
        "                max_tokens=self.max_tokens,\n",
        "                openai_api_key=self.openai_key,\n",
        "            )\n",
        "        else:\n",
        "            self.llm = OpenAI(\n",
        "                model_name=self.llm_type,\n",
        "                temperature=self.temperature,\n",
        "                max_tokens=self.max_tokens,\n",
        "                openai_api_key=self.openai_key,\n",
        "            )\n",
        "        self.embedder = OpenAIEmbeddings(model=emb, openai_api_key=self.openai_key)\n",
        "        try:\n",
        "            self.load_vectorstore(vector_store)\n",
        "        except Exception:\n",
        "            print(\n",
        "                \"Vectorstore invalid. Please load valid vectorstore or create new vectorstore.\"\n",
        "            )\n",
        "\n",
        "        self.prompt_template = prompt_template\n",
        "        self.questions = []\n",
        "        self.answers = []\n",
        "        self.sources = []\n",
        "        self.ground_truth = self.load_groundtruth(gt) if gt else None\n",
        "        self.drug_parser = PydanticOutputParser(pydantic_object=DrugOutput)\n",
        "        self.chain = None\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def load_vectorstore(self, vectorstore_path: str):\n",
        "        \"\"\"Load Vectorstore from path\n",
        "\n",
        "        Args:\n",
        "            vectorstore_path (str): Path to vector database folder.\n",
        "        \"\"\"\n",
        "        assert \"index.faiss\" in os.listdir(\n",
        "            vectorstore_path\n",
        "        ) and \"index.pkl\" in os.listdir(vectorstore_path), \"Invalid Vectorstore\"\n",
        "        self.docsearch = FAISS.load_local(vectorstore_path, self.embedder)\n",
        "        LOGGER.info(\"Successfully loaded existing vectorstore from local storage\")\n",
        "\n",
        "    def generate_vectorstore(\n",
        "        self,\n",
        "        data_directory: Optional[str] = None,\n",
        "        output_directory: str = \"./vectorstore\",\n",
        "        emb_store_type: str = \"faiss\",\n",
        "        chunk_size: int = 1000,\n",
        "        chunk_overlap: int = 250,\n",
        "        exclude_pages: Optional[Dict] = None,\n",
        "        pinecone_idx_name: Optional[str] = None,\n",
        "        additional_docs: Optional[str] = None,\n",
        "        key_path: Optional[str] = os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\"),\n",
        "    ):\n",
        "        \"\"\"Generate New vectorstore\n",
        "\n",
        "        Args:\n",
        "            data_directory (str): Directory contains source documents\n",
        "            output_directory (str, optional): Output directory of vector index database. Defaults to \"./vectorstore\".\n",
        "            emb_store_type (str, optional): Type of vector index database. Defaults to \"faiss\".\n",
        "            chunk_size (int, optional): Maximum size of text chunks (characters) after split. Defaults to 1000.\n",
        "            chunk_overlap (int, optional): Maximum overlapping window between text chunks. Defaults to 250.\n",
        "            exclude_pages (Optional[Dict], optional): Dictionary of pages to be excluded from documents. Defaults to None.\n",
        "            pinecone_idx_name (Optional[str], optional): Name of pinecone index to be created or loaded. Defaults to None.\n",
        "            additional_docs (Optional[str], optional): Additional Tables, Images or Json to be added to doc list. Defaults to None.\n",
        "            key_path (Optional[str], optional): Path to file containing API info.\n",
        "                Defaults to os.path.join(MAIN_DIR, \"auth\", \"api_keys.json\").\n",
        "        \"\"\"\n",
        "        self.docsearch = generate_vectorstore(\n",
        "            data_directory=data_directory,\n",
        "            embedder=self.embedder,\n",
        "            output_directory=output_directory,\n",
        "            emb_store_type=emb_store_type,\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "            exclude_pages=exclude_pages,\n",
        "            pinecone_idx_name=pinecone_idx_name,\n",
        "            additional_docs=additional_docs,\n",
        "            key_path=key_path,\n",
        "        )\n",
        "\n",
        "    def run_test_cases(\n",
        "        self, test_cases: Union[List[str], str], only_return_source: bool = False\n",
        "    ):\n",
        "        \"\"\"Run and save test cases to memory\n",
        "\n",
        "        Args:\n",
        "            test_cases (Union[List[str], str]): List of test queries.\n",
        "        \"\"\"\n",
        "        if isinstance(test_cases, str):\n",
        "            with open(test_cases, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "                test_cases = f.readlines()\n",
        "            test_cases = [test_case.rstrip() for test_case in test_cases]\n",
        "\n",
        "        if not self.chain:\n",
        "            self._create_retriever_chain()\n",
        "\n",
        "        if only_return_source:\n",
        "            LOGGER.info(\"Perform Semantic Search for Source Documents only (No QA).\")\n",
        "\n",
        "        for test_case in test_cases:\n",
        "            print(\"Query: {}\".format(test_case))\n",
        "            sources = []  # All sources for 1 single query\n",
        "            if only_return_source:\n",
        "                self.questions.append(test_case)\n",
        "                self.answers.append(None)\n",
        "                inputs = {\"question\": test_case}\n",
        "                source_documents = self.chain._get_docs(inputs)\n",
        "\n",
        "            else:\n",
        "                output = self.chain(test_case)\n",
        "                self.questions.append(output[\"question\"])\n",
        "                self.answers.append(output[\"answer\"])\n",
        "                source_documents = output[\"source_documents\"]\n",
        "\n",
        "            for document in source_documents:\n",
        "                sources.append(\n",
        "                    {\n",
        "                        \"title\": document.metadata[\"title\"],\n",
        "                        \"filename\": document.metadata[\"source\"].split(\"/\")[-1],\n",
        "                        \"page\": document.metadata[\"page\"],\n",
        "                        \"text\": document.page_content,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            self.sources.append(sources)\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_prompt_to_string(\n",
        "        prompt: Union[PromptTemplate, ChatPromptTemplate]\n",
        "    ) -> str:\n",
        "        \"\"\"Convert Prompt Object to string format\n",
        "\n",
        "        Args:\n",
        "            prompt (Union[PromptTemplate, ChatPromptTemplate]): Prompt Template\n",
        "\n",
        "        Returns:\n",
        "            str: Prompt String Template\n",
        "        \"\"\"\n",
        "        return prompt.format(**{v: v for v in prompt.input_variables})\n",
        "\n",
        "    @staticmethod\n",
        "    def process_source(source: Dict) -> str:\n",
        "        \"\"\"_summary_\n",
        "\n",
        "        Args:\n",
        "            source (Dict): Source Document Information\n",
        "\n",
        "        Returns:\n",
        "            str: Source Document Information in string\n",
        "        \"\"\"\n",
        "        return \"\\n\\n\".join([f\"{k}: {v}\" for k, v in source.items()])\n",
        "\n",
        "    def save_json(self, output_path: str):\n",
        "        \"\"\"Save Output of test case runs to json file\n",
        "\n",
        "        Args:\n",
        "            output_path (str): Output Path to json file.\n",
        "        \"\"\"\n",
        "        output_dict = {}\n",
        "        output_dict[\"prompt\"] = Experiment.convert_prompt_to_string(\n",
        "            self.prompt_template\n",
        "        )\n",
        "        output_dict[\"test_cases\"] = []\n",
        "\n",
        "        for question, answer, source in zip(self.questions, self.answers, self.sources):\n",
        "            output_dict[\"test_cases\"].append(\n",
        "                {\"question\": question, \"answer\": answer, \"sources\": source}\n",
        "            )\n",
        "\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump(output_dict, f)\n",
        "\n",
        "    def load_groundtruth(self, gt_path: str) -> pd.DataFrame:\n",
        "        \"\"\"Load Ground Truth information from .csv file\n",
        "\n",
        "        Args:\n",
        "            gt_path (str): Path to Ground Truth file\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame containing Ground Truth data.\n",
        "        \"\"\"\n",
        "        return pd.read_csv(gt_path, encoding=\"ISO-8859-1\")\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset queries and answers\"\"\"\n",
        "        self.questions = []\n",
        "        self.answers = []\n",
        "        self.sources = []\n",
        "        self.ground_truth = None\n",
        "\n",
        "    def load_json(self, json_path: str, reset: bool = False):\n",
        "        \"\"\"Load Queries and Answers from Json file\n",
        "\n",
        "        Args:\n",
        "            json_path (str): Path to json output file to load into instance\n",
        "            reset (bool, optional): If reset, clear queries and answers from memory before loading. Defaults to False.\n",
        "        \"\"\"\n",
        "        if reset:\n",
        "            self.reset()\n",
        "        with open(json_path, \"r\") as f:\n",
        "            input_dict = json.load(f)\n",
        "        for test_case in input_dict[\"test_cases\"]:\n",
        "            self.questions.append(test_case[\"question\"])\n",
        "            self.answers.append(test_case[\"answer\"])\n",
        "            self.sources.append(test_case[\"sources\"])\n",
        "\n",
        "    def write_csv(self, output_csv: str):\n",
        "        \"\"\"Write questions and answers to .csv files\n",
        "\n",
        "        Args:\n",
        "            output_csv (str): Path to output csv file\n",
        "        \"\"\"\n",
        "\n",
        "        pd_answers = [[], []]\n",
        "        pd_pros = [[], []]\n",
        "        pd_cons = [[], []]\n",
        "        pd_sources = [[], [], [], [], [], []]\n",
        "\n",
        "        for answer, sources in zip(self.answers, self.sources):\n",
        "            if answer:\n",
        "                drugs_info = re.findall(re.compile(r\"{[^{}]+}\"), answer)\n",
        "                drugs = []\n",
        "                for drug in drugs_info:\n",
        "                    try:\n",
        "                        drug = self.drug_parser.parse(drug)\n",
        "                        drugs.append(drug)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "            else:\n",
        "                drugs = []\n",
        "                \n",
        "            pd_answers[0].append(drugs[0].drug_name if len(drugs) > 0 else None)\n",
        "            pd_answers[1].append(drugs[1].drug_name if len(drugs) > 1 else None)\n",
        "            pd_pros[0].append(drugs[0].advantages if len(drugs) > 0 else None)\n",
        "            pd_cons[0].append(drugs[0].disadvantages if len(drugs) > 0 else None)\n",
        "            pd_pros[1].append(drugs[1].advantages if len(drugs) > 1 else None)\n",
        "            pd_cons[1].append(drugs[1].disadvantages if len(drugs) > 1 else None)\n",
        "\n",
        "            for idx, source in enumerate(sources):\n",
        "                pd_sources[idx].append(Experiment.process_source(source))\n",
        "\n",
        "            if idx + 1 < len(pd_sources):\n",
        "                for i in range(idx + 1, len(pd_sources)):\n",
        "                    pd_sources[i].append(None)\n",
        "\n",
        "        info = {\"question\": self.questions}\n",
        "\n",
        "        if self.ground_truth is not None:\n",
        "            info[\"gt_rec1\"] = self.ground_truth[\"Recommendation 1\"].tolist()\n",
        "            info[\"gt_rec2\"] = self.ground_truth[\"Recommendation 2\"].tolist()\n",
        "            info[\"gt_rec3\"] = self.ground_truth[\"Recommendation 3\"].tolist()\n",
        "            info[\"gt_avoid\"] = self.ground_truth[\"Drug Avoid\"].tolist()\n",
        "            info[\"gt_reason\"] = self.ground_truth[\"Reasoning\"].tolist()\n",
        "\n",
        "        info[\"prompt\"] = [\n",
        "            Experiment.convert_prompt_to_string(self.prompt_template)\n",
        "        ] * len(self.questions)\n",
        "        info[\"raw_answer\"] = self.answers\n",
        "        info[\"answer1\"] = pd_answers[0]\n",
        "        info[\"pro1\"] = pd_pros[0]\n",
        "        info[\"cons1\"] = pd_cons[0]\n",
        "        info[\"answer2\"] = pd_answers[1]\n",
        "        info[\"pro2\"] = pd_pros[1]\n",
        "        info[\"cons2\"] = pd_cons[1]\n",
        "        info[\"source1\"] = pd_sources[0]\n",
        "        info[\"source2\"] = pd_sources[1]\n",
        "        info[\"source3\"] = pd_sources[2]\n",
        "        info[\"source4\"] = pd_sources[3]\n",
        "        info[\"source5\"] = pd_sources[4]\n",
        "        info[\"source6\"] = pd_sources[5]\n",
        "\n",
        "        panda_df = pd.DataFrame(info)\n",
        "\n",
        "        panda_df.to_csv(output_csv, header=True)\n",
        "\n",
        "    def _create_retriever_chain(\n",
        "        self,\n",
        "        chain_type: str = \"stuff\",\n",
        "        return_source_documents: bool = True,\n",
        "        reduce_k_below_max_tokens: bool = True,\n",
        "    ):\n",
        "        \"\"\"Initiate QA from Source Chain\n",
        "\n",
        "        Args:\n",
        "            chain_type (str, optional): Chain Type. Can be stuff|map_reduce|refine|map_rerank. Defaults to \"stuff\".\n",
        "            return_source_documents (bool, optional): Whether to return source documents along side answers. Defaults to True.\n",
        "            reduce_k_below_max_tokens (bool, optional): If True, automatically reduce the number of source documents to\n",
        "                ensure that total tokens below max_tokens limit. Defaults to True.\n",
        "        \"\"\"\n",
        "        self.chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "            llm=self.llm,\n",
        "            chain_type=chain_type,\n",
        "            retriever=self.docsearch.as_retriever(),\n",
        "            return_source_documents=return_source_documents,\n",
        "            chain_type_kwargs={\"prompt\": self.prompt_template},\n",
        "            reduce_k_below_max_tokens=reduce_k_below_max_tokens,\n",
        "            verbose=self.verbose,\n",
        "        )\n",
        "        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CBLfxKVohLSS"
      },
      "source": [
        "# Create Vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXCLUDE_DICT = {\n",
        "    \"agrawal.pdf\": [13, 14, 15, 16, 17, 18],\n",
        "    \"PIIS1542356520300446.pdf\": [12, 13, 14, 15, 16, 17, 18],\n",
        "    \"gutjnl-2021-326390R2 CLEAN.pdf\": [0, 2, 31, 32, 33, 34, 35, 36,\n",
        "                                       37, 38, 39, 40, 41, 42, 43, 44, 45]\\\n",
        "                                        + list(range(3, 31)),\n",
        "    \"otad009.pdf\": [15, 16],\n",
        "    \"1-s2.0-S2468125321003770-main.pdf\": [9],\n",
        "    \"juillerat 2022.pdf\": [6, 7, 8],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of documents in datastore: 6\n",
            "Index 1: /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/1-s2.0-S2468125321003770-main.pdf\n",
            "Index 2: /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/agrawal.pdf\n",
            "Index 3: /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/gutjnl-2021-326390R2 CLEAN.pdf\n",
            "Index 4: /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/juillerat 2022.pdf\n",
            "Index 5: /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/otad009.pdf\n",
            "Index 6: /mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/PIIS1542356520300446.pdf\n"
          ]
        }
      ],
      "source": [
        "datastore_paths = [os.path.join(DOCUMENT_SOURCE, PROJECT, file_name) for file_name in os.listdir(os.path.join(DOCUMENT_SOURCE, PROJECT)) if file_name.endswith(\".pdf\")]\n",
        "print(\"Number of documents in datastore:\", len(datastore_paths))\n",
        "for i, path in enumerate(datastore_paths):\n",
        "    print(f\"Index {i + 1}: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of pages: 10\n",
            "{'source': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/1-s2.0-S2468125321003770-main.pdf', 'file_path': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/1-s2.0-S2468125321003770-main.pdf', 'page': 4, 'total_pages': 10, 'format': 'PDF 1.7', 'title': 'Efficacy and safety of biologics and small molecule drugs for patients with moderate-to-severe ulcerative colitis: a systematic review and network meta-analysis', 'author': 'Juan S Lasa MD', 'subject': 'The Lancet Gastroenterology & Hepatology, 7 (2022) 161-170. doi:10.1016/S2468-1253(21)00377-0', 'keywords': '', 'creator': 'Elsevier', 'producer': 'Acrobat Distiller 6.0 for Windows', 'creationDate': \"D:20211223225432+05'30'\", 'modDate': \"D:20220108175830+05'30'\", 'trapped': ''}\n",
            "\n",
            "Text Length: 5743\n",
            "\n",
            "('Articles\\n'\n",
            " 'www.thelancet.com/gastrohep   Vol 7   February 2022 \\n'\n",
            " '165\\n'\n",
            " 'U-ACCOMPLISH8). No phase 3 RCTs with etrasimod or \\n'\n",
            " 'TD-1473 were found.\\n'\n",
            " 'Among 22 studies evaluating maintenance therapy, ten \\n'\n",
            " 'were done by use of a treat-straight-through strategy \\n'\n",
            " '(2528 patients)19–22,24,25,29,34,36 and 12 followed a randomised \\n'\n",
            " 'responders design (3484 patients).6,27,28,30–32,35,37–41 Only seven \\n'\n",
            " 'studies evaluated histological remission.6,29,31,32,35,38,41 The \\n'\n",
            " 'main characteristics of the included trials are described \\n'\n",
            " 'in the appendix (pp 2–4). All outcomes were assessed \\n'\n",
            " 'uniformly on the basis of the standard definition of the \\n'\n",
            " 'Mayo score, with follow-up durations of 6–14 weeks for \\n'\n",
            " 'induction therapy and 26–66 weeks for maintenance \\n'\n",
            " 'therapy (appendix pp 2–4). All studies were industry \\n'\n",
            " 'sponsored. A risk of bias assessment showed a low risk \\n'\n",
            " 'of bias for most of the included studies (appendix p 5). \\n'\n",
            " 'Confidence in the estimates derived from our meta-\\n'\n",
            " 'analysis is shown in the appendix (pp 6–8).\\n'\n",
            " 'A network ma')\n",
            "{'author': 'Juan S Lasa MD',\n",
            " 'creationDate': \"D:20211223225432+05'30'\",\n",
            " 'creator': 'Elsevier',\n",
            " 'file_path': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/1-s2.0-S2468125321003770-main.pdf',\n",
            " 'format': 'PDF 1.7',\n",
            " 'keywords': '',\n",
            " 'modDate': \"D:20220108175830+05'30'\",\n",
            " 'page': 4,\n",
            " 'producer': 'Acrobat Distiller 6.0 for Windows',\n",
            " 'source': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/1-s2.0-S2468125321003770-main.pdf',\n",
            " 'subject': 'The Lancet Gastroenterology & Hepatology, 7 (2022) 161-170. '\n",
            "            'doi:10.1016/S2468-1253(21)00377-0',\n",
            " 'title': 'Efficacy and safety of biologics and small molecule drugs for '\n",
            "          'patients with moderate-to-severe ulcerative colitis: a systematic '\n",
            "          'review and network meta-analysis',\n",
            " 'total_pages': 10,\n",
            " 'trapped': ''}\n"
          ]
        }
      ],
      "source": [
        "sample_path = datastore_paths[0]\n",
        "\n",
        "sample_data = load_single_document(sample_path)\n",
        "print(\"Number of pages:\", len(sample_data))\n",
        "sample_page = sample_data[4]\n",
        "print(str(sample_page.metadata) + \"\\n\")\n",
        "content = sample_page.page_content\n",
        "print(f\"Text Length: {len(content)}\\n\")\n",
        "# content = re.sub(r\"\\t+\", \" \", content)\n",
        "pprint(content[:1000])\n",
        "metadata = sample_page.metadata\n",
        "pprint(metadata)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ada-Text-Embeddings-2 Text Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "EMB_MODEL = OpenAIEmbeddings(openai_api_key = OPENAI_KEY)\n",
        "SOURCE_DATA = os.path.join(DOCUMENT_SOURCE, PROJECT)\n",
        "DATABASE_PATH = os.path.join(EMBSTORE_DIR, PROJECT,\n",
        "                                \"faiss\", \"text-embedding-ada-002\", \"test\")\n",
        "EMBSTORE_TYPE=\"faiss\"\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpY5T1luxwJY"
      },
      "outputs": [],
      "source": [
        "generate_vectorstore(\n",
        "    embeddings=EMB_MODEL,\n",
        "    source_directory=SOURCE_DATA,\n",
        "    output_directory=DATABASE_PATH,\n",
        "    emb_store_type=EMBSTORE_TYPE,\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP,\n",
        "    exclude_pages=EXCLUDE_DICT)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ada-Text-Embeddings-2: Text + Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Efficacy of biological treatments according to the line of treatment, earlier exposure, disease phenotype and patient characteristics. \\n\\nPatient Profile: Fresh No previous treatment\\nBest: Infliximab (IFX*)\\n2nd Best: Vedoluzimab (VEDO)\\n3rd Best: Ustekinumab (USTE)\\n4th Best: Golimumab (GOL)\\n5th Best: Adalimumab (ADA)\\n\\nPatient Profile: Currently under maintenance\\nBest: Vedoluzimab (VEDO)\\n2nd Best: Infliximab (IFX)\\n3rd Best: Ustekinumab (USTE), Golimumab (GOL)\\n4th Best: Adalimumab (ADA)\\n5th Best: \\n\\nPatient Profile: Prior response to Infliximab\\nBest: Golimumab (GOL)\\n2nd Best: Adalimumab (ADA)\\n3rd Best: Ustekinumab (USTE), Vedoluzimab (VEDO)\\n4th Best: \\n5th Best: \\n\\nPatient Profile: Prior failure to Anti-TNF agents (1-2x) (PNR)\\nBest: Ustekinumab (USTE)\\n2nd Best: Vedoluzimab (VEDO)\\n3rd Best: \\n4th Best: \\n5th Best: \\n\\nPatient Profile: Prior failure to Vedolizumab\\nBest: Infliximab (IFX)\\n2nd Best: Ustekinumab (USTE), Golimumab (GOL)\\n3rd Best: Adalimumab (ADA)\\n4th Best: \\n5th Best: \\n\\nPatient Profile: Age > 65 & comorbidities (safety aspects data)\\nBest: Ustekinumab (USTE), Vedoluzimab (VEDO)\\n2nd Best: Golimumab (GOL), Infliximab (IFX), Adalimumab (ADA)\\n3rd Best: \\n4th Best: \\n5th Best: \\n\\nPatient Profile: Pregnancy\\nBest: Infliximab (IFX)\\n2nd Best: Golimumab (GOL), Adalimumab (ADA)\\n3rd Best: Ustekinumab (USTE), Vedoluzimab (VEDO)\\n4th Best: \\n5th Best: \\n\\nPatient Profile: Extraintestinale manifestation\\nBest: Infliximab (IFX)\\n2nd Best: Golimumab (GOL)\\n3rd Best: Adalimumab (ADA)\\n4th Best: Ustekinumab (USTE)\\n5th Best: Vedoluzimab (VEDO)\\n\\nPatient Profile: Pouchitis\\nBest: Vedoluzimab (VEDO)\\n2nd Best: Adalimumab (ADA)\\n3rd Best: Infliximab (IFX)\\n4th Best: Ustekinumab (USTE)\\n5th Best: Golimumab (GOL)\\n\\n', metadata={'author': 'Pascal Juillerat', 'creator': 'Elsevier', 'file_path': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/juillerat 2022.pdf', 'page': 3, 'source': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/juillerat 2022.pdf', 'subject': 'Current Research in Pharmacology and Drug Discovery, 3 (2022) 100104. doi:10.1016/j.crphar.2022.100104', 'title': 'Positioning biologics in the treatment of IBD: A practical guide - Which mechanism of action for whom?', 'total_pages': 9}),\n",
              " Document(page_content='Stratification of inflammatory bowel disease risk of progression based on disease severity and activity. BMI, body mass index; CDAI, Crohns Disease Activity Index; ESR, erythrocyte sedimentation rate; UCEIS, Ulcerative Colitis Endoscopic Index of Severity.\\n\\n: Remission\\nStools (no./d): Formed stool\\nBlood in stools: None\\nUrgency: None\\nHemoglobin: Normal\\nESR: 30\\nCRP (mg/L): Normal\\nFC (ug/g): < 150-200\\nEndoscopy (Mayo subscore): O\\x971\\nUCEIS: O\\x971\\n\\n: Mild\\nStools (no./d): < 4\\nBlood in stools: Intermittent\\nUrgency: Mild, occasional\\nHemoglobin: Normal\\nESR: 30\\nCRP (mg/L): Elevated\\nFC (ug/g): > 150-200\\nEndoscopy (Mayo subscore): 1\\nUCEIS: 2\\x974\\n\\n: Moderate\\nStools (no./d): > 6\\nBlood in stools: Frequent\\nUrgency: Often\\nHemoglobin: 75% of normal\\nESR: 30\\nCRP (mg/L): Elevated\\nFC (ug/g): 150-200\\nEndoscopy (Mayo subscore): 2\\x973\\nUCEIS: 5\\x978\\n\\n: Severe\\nStools (no./d): > 10\\nBlood in stools: Continuous\\nUrgency: Continuous\\nHemoglobin: Transfusions required\\nESR: 30\\nCRP (mg/L): Elevated\\nFC (ug/g): > 150\\x97200\\nEndoscopy (Mayo subscore): 3\\nUCEIS: 7\\x978\\n\\n', metadata={'author': 'Manasi Agrawal', 'creator': 'Elsevier', 'file_path': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/agrawal.pdf', 'page': 5, 'source': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/agrawal.pdf', 'subject': 'Gastroenterology, 161 (2021) 47-65. doi:10.1053/j.gastro.2021.04.063', 'title': 'Approach to the Management of Recently Diagnosed Inflammatory Bowel Disease Patients: A Users Guide for Adult and Pediatric Gastroenterologists', 'total_pages': 19}),\n",
              " Document(page_content='Therapeutic strategies for the management of recentlydiagnosedulcerative colitis. IMMs include thiopurines and methotrexate. 5-ASA, 5-amino salicylic acid; ASUC, acute severe ulcerative colitis; IPAA, ileal pouch anal anastomosis.\\n\\nRisk stratification: Mild\\nClinical features: NA\\nTreatment options: 5-ASA (oral and/or topical)\\n\\nRisk stratification: Moderate\\nClinical features: NA\\nTreatment options: Can consider 5-ASA (with rapid step-up if inadequate response)\\n\\nRisk stratification: Moderate\\nClinical features: NA\\nTreatment options: VDZ or UST\\n\\nRisk stratification: Moderate\\nClinical features: NA\\nTreatment options: Thiopurine\\n\\nRisk stratification: Moderate\\nClinical features: NA\\nTreatment options: TNFi +/- IMM\\n\\nRisk stratification: Severe\\nClinical features: NA\\nTreatment options: TNFi +/- IMM\\n\\nRisk stratification: Severe\\nClinical features: NA\\nTreatment options: Subtotal colectomy + IPAA or cyclosporine (for ASUC)\\n\\nRisk stratification: Additional consideration: EIM present\\nClinical features: Psoriasis or psoriatic arthritis\\nTreatment options: UST\\n\\nRisk stratification: Additional consideration: EIM present\\nClinical features: Other arthritis\\nTreatment options: TNFi\\n\\n', metadata={'author': 'Manasi Agrawal', 'creator': 'Elsevier', 'file_path': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/agrawal.pdf', 'page': 7, 'source': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/document_store/uc/agrawal.pdf', 'subject': 'Gastroenterology, 161 (2021) 47-65. doi:10.1053/j.gastro.2021.04.063', 'title': 'Approach to the Management of Recently Diagnosed Inflammatory Bowel Disease Patients: A Users Guide for Adult and Pediatric Gastroenterologists', 'total_pages': 19})]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_docs_path = os.path.join(MAIN_DIR, \"data/additional_docs.json\")\n",
        "\n",
        "with open(add_docs_path, \"r\") as f:\n",
        "    additional_documents = json.load(f)\n",
        "    \n",
        "ADD_DOCS = []\n",
        "for table_info in additional_documents:\n",
        "    ADD_DOCS.extend(convert_csv_to_documents(table_info))\n",
        "    \n",
        "ADD_DOCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "EMB_MODEL = OpenAIEmbeddings(openai_api_key = OPENAI_KEY)\n",
        "SOURCE_DATA = os.path.join(DOCUMENT_SOURCE, PROJECT)\n",
        "DATABASE_PATH = os.path.join(EMBSTORE_DIR, PROJECT,\n",
        "                                \"faiss\", \"text-embedding-ada-002\", \"v2-add\")\n",
        "EMBSTORE_TYPE=\"faiss\"\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain.vectorstores.faiss.FAISS at 0x7f0afde5cdc0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_vectorstore(\n",
        "    embeddings=OpenAIEmbeddings(openai_api_key = OPENAI_KEY),\n",
        "    source_directory=os.path.join(DOCUMENT_SOURCE, PROJECT),\n",
        "    output_directory=DATABASE_PATH,\n",
        "    emb_store_type=\"faiss\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=250,\n",
        "    exclude_pages=EXCLUDE_DICT,\n",
        "    additional_docs=ADD_DOCS)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WPyXW-l24VFg"
      },
      "source": [
        "# Prototypes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "933ywV6FSiC5"
      },
      "source": [
        "## Test Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu4Fey58rXx9",
        "outputId": "a754067e-4c25-48f3-9dca-7c8469342949"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['40 year old male with newly diagnosed moderate UC and articular extraintestinal manifestations',\n",
              " '70 year old female with newly diagnosed severe UC',\n",
              " '35 year old male with known moderate UC with prior exposure to infliximab but has worsening colitis on endoscopy despite compliance',\n",
              " '60 year old female with newly diagnosed moderate UC with a background of congestive cardiac failure',\n",
              " '38 year old female with newly diagnosed moderate UC and psoriasis',\n",
              " '25 year old pregnant woman with severe distal ulcerative colitis',\n",
              " '56 year old man with moderate to severe ulcerative colitis and ankylosing spondylitis',\n",
              " '38 year old man with severe ulcerative colitis and has lost response to vedolizumab',\n",
              " '28 year old woman who has severe extensive ulcerative colitis and has a history of lymphoma which was treated 4 years ago',\n",
              " '36 year old woman with moderate ulcerative colitis and multiple sclerosis']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(osp.join(DATA_DIR, \"queries\", \"uc.txt\"), \"r\", encoding = \"utf-8-sig\") as f:\n",
        "    test_cases = f.readlines()\n",
        "\n",
        "test_cases = [test_case.rstrip() for test_case in test_cases]\n",
        "test_cases"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2fY1Hyjd5mb7"
      },
      "source": [
        "## Experiment 1: Only Text - Normal Prompt Template - GPT4"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5DLq8oet-_Av"
      },
      "source": [
        "### Prompt Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX3gOJr9I3AN",
        "outputId": "5c51fc3d-af94-4586-e9dd-8dffb71b6eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
            "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC). Perform the following step\n",
            "\n",
            "ANALYSE the given patient profile based on given query based on one of the following criteria:\n",
            "- Freshly treated patient or patient under maintenance\n",
            "- Prior response to Infliximab\n",
            "- Prior failure to Anti-TNF agents\n",
            "- Prior failure to Vedolizumab\n",
            "- Age\n",
            "- Pregnancy\n",
            "- Extraintestinale manifestations\n",
            "- Pouchitis\n",
            "\n",
            "FINALLY RETURN up to 2 TOP choices of biological drugs given patient profile. Explain the PROS and CONS of the 2 choices.\n",
            "\n",
            "Summaries\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"drug_name\": {\"title\": \"Drug Name\", \"description\": \"Name of the drug\", \"type\": \"string\"}, \"advantages\": {\"title\": \"Advantages\", \"description\": \"Advantages of the drug \", \"type\": \"string\"}, \"disadvantages\": {\"title\": \"Disadvantages\", \"description\": \"Disadvantages of the drug\", \"type\": \"string\"}}, \"required\": [\"drug_name\", \"advantages\", \"disadvantages\"]}\n",
            "```\n",
            "\n",
            "Question: User Query\n",
            "Answer:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### STANDARD PROMPT TEMPLATE\n",
        "drug_parser = PydanticOutputParser(pydantic_object=DrugOutput)\n",
        "\n",
        "prompt_template = \"\"\"Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
        "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC). Perform the following step\n",
        "\n",
        "ANALYSE the given patient profile based on given query based on one of the following criteria:\n",
        "- Freshly treated patient or patient under maintenance\n",
        "- Prior response to Infliximab\n",
        "- Prior failure to Anti-TNF agents\n",
        "- Prior failure to Vedolizumab\n",
        "- Age\n",
        "- Pregnancy\n",
        "- Extraintestinale manifestations\n",
        "- Pouchitis\n",
        "\n",
        "FINALLY RETURN up to 2 TOP choices of biological drugs given patient profile. Explain the PROS and CONS of the 2 choices.\n",
        "\n",
        "{summaries}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "TEST_PROMPT_TEMPLATE_1 = PromptTemplate(\n",
        "    template = prompt_template,\n",
        "    input_variables = [\"summaries\", \"question\"],\n",
        "    partial_variables={\"format_instructions\": drug_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "print(TEST_PROMPT_TEMPLATE_1.format(summaries = \"Summaries\", question = \"User Query\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aqUPpf1JDd1"
      },
      "source": [
        "### Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Xd_LvsydJzdp"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "LLM_TYPE = \"gpt-4\"\n",
        "DESCRIPTION = \"Text_Only\"\n",
        "MAX_TOKENS = 1024\n",
        "TIME = datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "VERBOSE = True\n",
        "save_path = osp.join(ARTIFACT_DIR, f\"{LLM_TYPE}_{DESCRIPTION}_{TIME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-tAQR6i7BVw"
      },
      "outputs": [],
      "source": [
        "# Create and run experiment\n",
        "exp1 = Experiment(\n",
        "    prompt_template = TEST_PROMPT_TEMPLATE_1,\n",
        "    vector_store = EMBSTORE_DIR,\n",
        "    llm_type = LLM_TYPE,\n",
        "    max_tokens = MAX_TOKENS,\n",
        "    gt = osp.join(MAIN_DIR, \"ground_truth.csv\"),\n",
        "    verbose = VERBOSE\n",
        ")\n",
        "\n",
        "exp1.run_test_cases(test_cases)\n",
        "\n",
        "# Save Output\n",
        "exp1.save_json(save_path+\".json\")\n",
        "exp1.write_csv(save_path+\".csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KHu-zQcL-26D"
      },
      "source": [
        "## Experiment 2: Only Text - CHAT Prompt Template - GPT4"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5EPzgAOO_Jkp"
      },
      "source": [
        "### Prompt Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3spHEtJ06cce",
        "outputId": "1655a9f6-4ec5-488c-93ff-e9d33a6aa75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System: \n",
            "Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
            "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC).\n",
            "\n",
            "ANALYSE the given patient profile based on given query based on one of the following criteria:\n",
            "- Whether treated patient is new patient or patient under maintenance\n",
            "- Prior response to Infliximab\n",
            "- Prior failure to Anti-TNF agents\n",
            "- Prior failure to Vedolizumab\n",
            "- Age\n",
            "- Pregnancy\n",
            "- Extraintestinale manifestations\n",
            "- Pouchitis\n",
            "\n",
            "FINALLY RETURN up to 2 TOP choices of biological drugs given patient profile. Explain the PROS and CONS of the 2 choices.\n",
            "Output your answer as a list of JSON objects with keys: drug_name, advantages, disadvantages.\n",
            "\n",
            "Summaries\n",
            "\n",
            "\n",
            "Human: User Query\n"
          ]
        }
      ],
      "source": [
        "### CHAT PROMTP TEMPLATE\n",
        "system_prompt = \"\"\"\n",
        "Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
        "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC).\n",
        "\n",
        "ANALYSE the given patient profile based on given query based on one of the following criteria:\n",
        "- Whether treated patient is new patient or patient under maintenance\n",
        "- Prior response to Infliximab\n",
        "- Prior failure to Anti-TNF agents\n",
        "- Prior failure to Vedolizumab\n",
        "- Age\n",
        "- Pregnancy\n",
        "- Extraintestinale manifestations\n",
        "- Pouchitis\n",
        "\n",
        "FINALLY RETURN up to 2 TOP choices of biological drugs given patient profile. Explain the PROS and CONS of the 2 choices.\n",
        "Output your answer as a list of JSON objects with keys: drug_name, advantages, disadvantages.\n",
        "\n",
        "{summaries}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "TEST_PROMPT_TEMPLATE_2 = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(system_prompt, input_variables = [\"summaries\"]),\n",
        "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(TEST_PROMPT_TEMPLATE_2.format(summaries = \"Summaries\", question = \"User Query\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mhDSVNKT_Xrs"
      },
      "source": [
        "### Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do9b9jEu_Xr-"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "LLM_TYPE = \"gpt-3.5-turbo\"\n",
        "DESCRIPTION = \"Text_Only_With_CHAT_Prompt\"\n",
        "MAX_TOKENS = 1024\n",
        "TIME = datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "VERBOSE = True\n",
        "save_path = osp.join(ARTIFACT_DIR, f\"{LLM_TYPE}_{DESCRIPTION}_{TIME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwDbSTHV_Xr-",
        "outputId": "dbb9b128-f1a6-40f7-ee7a-a6523ff32e49"
      },
      "outputs": [],
      "source": [
        "# Create and run experiment\n",
        "exp2 = Experiment(\n",
        "    prompt_template = TEST_PROMPT_TEMPLATE_2,\n",
        "    vector_store = EMBSTORE_DIR,\n",
        "    llm_type = LLM_TYPE,\n",
        "    max_tokens = MAX_TOKENS,\n",
        "    gt = osp.join(MAIN_DIR, \"ground_truth.csv\"),\n",
        "    verbose = VERBOSE\n",
        ")\n",
        "\n",
        "exp2.run_test_cases(test_cases)\n",
        "\n",
        "# Save Output\n",
        "exp2.save_json(save_path+\".json\")\n",
        "exp2.write_csv(save_path+\".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2gcEn-8aYpp",
        "outputId": "a386b037-96ec-4bdf-e01b-7f64c4ae0c57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Successfully loaded existing vectorstore from local storage\n"
          ]
        }
      ],
      "source": [
        "# Create and run experiment\n",
        "exp2 = Experiment(\n",
        "    prompt_template = TEST_PROMPT_TEMPLATE_2,\n",
        "    vector_store = EMBSTORE_DIR,\n",
        "    llm_type = LLM_TYPE,\n",
        "    max_tokens = MAX_TOKENS,\n",
        "    gt = osp.join(MAIN_DIR, \"ground_truth.csv\"),\n",
        "    verbose = VERBOSE\n",
        ")\n",
        "\n",
        "exp2.load_json(save_path + \".json\")\n",
        "\n",
        "# Save Output\n",
        "exp2.write_csv(save_path+\".csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-AGiFA7-VosO"
      },
      "source": [
        "## Experiment 3 - Added Table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
            "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC). Perform the following step\n",
            "\n",
            "ANALYSE the given patient profile based on given query based on one of the following criteria:\n",
            "- Freshly treated patient or patient under maintenance\n",
            "- Prior response to Infliximab\n",
            "- Prior failure to Anti-TNF agents\n",
            "- Prior failure to Vedolizumab\n",
            "- Age\n",
            "- Pregnancy\n",
            "- Extraintestinale manifestations\n",
            "- Pouchitis\n",
            "\n",
            "FINALLY RETURN up to 2 TOP choices of biological drugs given patient profile. Explain the PROS and CONS of the 2 choices.\n",
            "\n",
            "Summaries\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"drug_name\": {\"title\": \"Drug Name\", \"description\": \"Name of the drug\", \"type\": \"string\"}, \"advantages\": {\"title\": \"Advantages\", \"description\": \"Advantages of the drug \", \"type\": \"string\"}, \"disadvantages\": {\"title\": \"Disadvantages\", \"description\": \"Disadvantages of the drug\", \"type\": \"string\"}}, \"required\": [\"drug_name\", \"advantages\", \"disadvantages\"]}\n",
            "```\n",
            "\n",
            "Question: User Query\n",
            "Answer:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### STANDARD PROMPT TEMPLATE\n",
        "drug_parser = PydanticOutputParser(pydantic_object=DrugOutput)\n",
        "\n",
        "prompt_template = \"\"\"Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
        "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC). Perform the following step\n",
        "\n",
        "ANALYSE the given patient profile based on given query based on one of the following criteria:\n",
        "- Freshly treated patient or patient under maintenance\n",
        "- Prior response to Infliximab\n",
        "- Prior failure to Anti-TNF agents\n",
        "- Prior failure to Vedolizumab\n",
        "- Age\n",
        "- Pregnancy\n",
        "- Extraintestinale manifestations\n",
        "- Pouchitis\n",
        "\n",
        "FINALLY RETURN up to 2 TOP choices of biological drugs given patient profile. Explain the PROS and CONS of the 2 choices.\n",
        "\n",
        "{summaries}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "TEST_PROMPT_TEMPLATE_3 = PromptTemplate(\n",
        "    template = prompt_template,\n",
        "    input_variables = [\"summaries\", \"question\"],\n",
        "    partial_variables={\"format_instructions\": drug_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "print(TEST_PROMPT_TEMPLATE_3.format(summaries = \"Summaries\", question = \"User Query\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Settings\n",
        "LLM_TYPE = \"gpt-4\"\n",
        "DESCRIPTION = \"With Some Tables\"\n",
        "MAX_TOKENS = 1024\n",
        "TIME = datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "VERBOSE = True\n",
        "VECTORSTORE = os.path.join(EMBSTORE_DIR, PROJECT, \"faiss\", \"text-embedding-ada-002\", \"v2-add-rows_1000_200\")\n",
        "save_path = osp.join(ARTIFACT_DIR, f\"{LLM_TYPE}_{DESCRIPTION}_{TIME}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and run experiment\n",
        "exp3 = Experiment(\n",
        "    prompt_template = TEST_PROMPT_TEMPLATE_3,\n",
        "    vector_store = VECTORSTORE,\n",
        "    llm_type = LLM_TYPE,\n",
        "    max_tokens = MAX_TOKENS,\n",
        "    gt = osp.join(MAIN_DIR, \"ground_truth.csv\"),\n",
        "    verbose = VERBOSE\n",
        ")\n",
        "\n",
        "exp3.run_test_cases(test_cases)\n",
        "\n",
        "# Save Output\n",
        "exp3.save_json(save_path+\".json\")\n",
        "exp3.write_csv(save_path+\".csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4 - Changing to Different Settings\n",
        "\n",
        "### uc-3:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_1.py\n",
        "- faiss/text-embedding-ada-002/v2-add-rows_1000_200\n",
        "\n",
        "### uc-4:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_1.py\n",
        "- faiss/text-embedding-ada-002/v3-add-rows_2500_500\n",
        "\n",
        "### uc-5:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_1.py\n",
        "- faiss/text-embedding-ada-002/v4-add-tables_1000_200\n",
        "\n",
        "### uc-6:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_1.py\n",
        "- faiss/text-embedding-ada-002/v5-add-tables_2500_500\n",
        "\n",
        "### uc-7:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_1.py\n",
        "- faiss/text-embedding-ada-002/v6-add-tables_750_100\n",
        "\n",
        "### uc-8:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_2.py\n",
        "- faiss/text-embedding-ada-002/v5-add-tables_2500_500\n",
        "\n",
        "### uc-1_chat:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_chat_1.py\n",
        "- faiss/text-embedding-ada-002/v5-add-tables_2500_500\n",
        "\n",
        "### uc-2_chat:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_chat_1.py\n",
        "- faiss/text-embedding-ada-002/v3-add-rows_2500_500\n",
        "\n",
        "### uc-3_chat:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_chat_1.py\n",
        "- faiss/text-embedding-ada-002/v4-add-tables_1000_200\n",
        "\n",
        "### uc-4_chat:\n",
        "- test_case: data/queries/uc.txt\n",
        "- prompt: uc_qa_source_chat_2.py\n",
        "- faiss/text-embedding-ada-002/v5-add-tables_2500_500\n",
        "\n",
        "### uc-5_chat:\n",
        "- test_case: data/queries/uc_long.txt\n",
        "- prompt: uc_qa_source_chat_3.py\n",
        "- faiss/text-embedding-ada-002/v5-add-tables_2500_500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! ./src/bash/multi_exps.sh uc_7.yaml uc_8_chat.yaml uc_4_chat.yaml uc_5_chat.yaml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 5 - Map Reduce"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QA with semantic search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Settings\n",
        "LLM_TYPE = \"gpt-4\"\n",
        "DESCRIPTION = \"Map_Reduce_1_Prompt_Pregnant\"\n",
        "MAX_TOKENS = 1024\n",
        "TIME = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
        "VERBOSE = True\n",
        "VECTORSTORE = os.path.join(EMBSTORE_DIR, PROJECT, \"faiss\",\n",
        "                           \"text-embedding-ada-002\",\"v5-add-tables_2500_500\")\n",
        "save_path = osp.join(ARTIFACT_DIR, f\"{LLM_TYPE}_{DESCRIPTION}_{TIME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "human_prompt = \"\"\"\n",
        "=========\n",
        "QUESTION: {question}\n",
        "=========\n",
        "\"\"\"\n",
        "\n",
        "pregnancy_prompt = \"\"\"Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
        "=========\n",
        "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC). Perform the following steps\n",
        "1. Identify if patient is pregnant.\n",
        "2. Search from REFERENCE TEXT the best biological drugs based on whether patient is pregnant.\n",
        "3. Return up to 2 TOP choices of biological drugs with the PROS and CONS of the 2 choices.\n",
        "\n",
        "=========\n",
        "REFERENCE TEXT:\n",
        "{summaries}\n",
        "\"\"\"\n",
        "\n",
        "PREGNANCY_PROMPT_TEMPLATE = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            pregnancy_prompt, input_variables=[\"summaries\"]\n",
        "        ),\n",
        "        HumanMessagePromptTemplate.from_template(human_prompt),\n",
        "    ]\n",
        ")\n",
        "\n",
        "age_prompt = \"\"\"Make reference to the context given to assess the scenario. If you do not know the answer. just say that \"I don't know\", don't try to make up an answer.\n",
        "=========\n",
        "You are a physician assistant giving advice on treatment for moderate to severe ulcerative colitis (UC). Perform the following steps\n",
        "1. Identify from user input the age of patient, if applicable.\n",
        "2. Search from REFERENCE TEXT the best biological drugs based on patient's age.\n",
        "3. Return up to 2 TOP choices of biological drugs with the PROS and CONS of the 2 choices.\n",
        "\n",
        "=========\n",
        "REFERENCE TEXT:\n",
        "{summaries}\n",
        "\"\"\"\n",
        "\n",
        "AGE_PROMPT_TEMPLATE = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            age_prompt, input_variables=[\"summaries\"]\n",
        "        ),\n",
        "        HumanMessagePromptTemplate.from_template(human_prompt),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 40 year old male with newly diagnosed moderate UC and articular extraintestinal manifestations\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 70 year old female with newly diagnosed severe UC\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 35 year old male with known moderate UC with prior exposure to infliximab but has worsening colitis on endoscopy despite compliance\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 60 year old female with newly diagnosed moderate UC with a background of congestive cardiac failure\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 38 year old female with newly diagnosed moderate UC and psoriasis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 25 year old pregnant woman with severe distal ulcerative colitis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 56 year old man with moderate to severe ulcerative colitis and ankylosing spondylitis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 38 year old man with severe ulcerative colitis and has lost response to vedolizumab\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 28 year old woman who has severe extensive ulcerative colitis and has a history of lymphoma which was treated 4 years ago\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 36 year old woman with moderate ulcerative colitis and multiple sclerosis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "exp5_pregnant =  Experiment(\n",
        "    prompt_template = PREGNANCY_PROMPT_TEMPLATE,\n",
        "    vector_store = VECTORSTORE,\n",
        "    llm_type = LLM_TYPE,\n",
        "    max_tokens = MAX_TOKENS,\n",
        "    verbose = VERBOSE\n",
        ")\n",
        "\n",
        "exp5_pregnant.run_test_cases(test_cases)\n",
        "settings = {\n",
        "    \"project\": PROJECT,\n",
        "    \"test_case\": osp.join(DATA_DIR, \"queries\", \"uc.txt\"),\n",
        "    \"prompt\": \"individual_prompts.py\",\n",
        "    \"ground_truth\": \"uc_gt.csv\",\n",
        "    \"description\": DESCRIPTION,\n",
        "    \"verbose\": True,\n",
        "\n",
        "    \"emb_type\": \"text-embedding-ada-002\",\n",
        "    \"vectorstore\": VECTORSTORE,\n",
        "    \"chunk_size\": 2500,\n",
        "    \"chunk_overlap\": 500,\n",
        "    \"additional_docs\": None,\n",
        "    \"pinecone_index_name\": None,\n",
        "\n",
        "    \"llm_type\": \"gpt-4\",\n",
        "    \"temperature\": 0,\n",
        "    \"max_tokens\": MAX_TOKENS,\n",
        "}\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "exp5_pregnant.save_json(os.path.join(save_path, \"result.json\"))\n",
        "exp5_pregnant.write_csv(os.path.join(save_path, \"result.csv\"))\n",
        "with open(os.path.join(save_path, \"settings.yaml\"), \"w\") as f:\n",
        "    yaml.dump(settings, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Settings\n",
        "LLM_TYPE = \"gpt-4\"\n",
        "DESCRIPTION = \"Map_Reduce_1_Prompt_Age\"\n",
        "MAX_TOKENS = 1024\n",
        "TIME = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
        "VERBOSE = True\n",
        "VECTORSTORE = os.path.join(EMBSTORE_DIR, PROJECT, \"faiss\",\n",
        "                           \"text-embedding-ada-002\",\"v5-add-tables_2500_500\")\n",
        "save_path = osp.join(ARTIFACT_DIR, f\"{LLM_TYPE}_{DESCRIPTION}_{TIME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: 40 year old male with newly diagnosed moderate UC and articular extraintestinal manifestations\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 70 year old female with newly diagnosed severe UC\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 35 year old male with known moderate UC with prior exposure to infliximab but has worsening colitis on endoscopy despite compliance\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 60 year old female with newly diagnosed moderate UC with a background of congestive cardiac failure\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 38 year old female with newly diagnosed moderate UC and psoriasis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 25 year old pregnant woman with severe distal ulcerative colitis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 56 year old man with moderate to severe ulcerative colitis and ankylosing spondylitis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 38 year old man with severe ulcerative colitis and has lost response to vedolizumab\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 28 year old woman who has severe extensive ulcerative colitis and has a history of lymphoma which was treated 4 years ago\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query: 36 year old woman with moderate ulcerative colitis and multiple sclerosis\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "exp5_age =  Experiment(\n",
        "    prompt_template = AGE_PROMPT_TEMPLATE,\n",
        "    vector_store = VECTORSTORE,\n",
        "    llm_type = LLM_TYPE,\n",
        "    max_tokens = MAX_TOKENS,\n",
        "    verbose = VERBOSE\n",
        ")\n",
        "\n",
        "exp5_age.run_test_cases(test_cases)\n",
        "settings = {\n",
        "    \"project\": PROJECT,\n",
        "    \"test_case\": osp.join(DATA_DIR, \"queries\", \"uc.txt\"),\n",
        "    \"prompt\": \"individual_prompts.py\",\n",
        "    \"ground_truth\": \"uc_gt.csv\",\n",
        "    \"description\": \"Map_Reduce_1_Prompt_Age\",\n",
        "    \"verbose\": True,\n",
        "\n",
        "    \"emb_type\": \"text-embedding-ada-002\",\n",
        "    \"vectorstore\": VECTORSTORE,\n",
        "    \"chunk_size\": 2500,\n",
        "    \"chunk_overlap\": 500,\n",
        "    \"additional_docs\": None,\n",
        "    \"pinecone_index_name\": None,\n",
        "\n",
        "    \"llm_type\": \"gpt-4\",\n",
        "    \"temperature\": 0,\n",
        "    \"max_tokens\": MAX_TOKENS,\n",
        "}\n",
        "\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "exp5_age.save_json(os.path.join(save_path, \"result.json\"))\n",
        "exp5_age.write_csv(os.path.join(save_path, \"result.csv\"))\n",
        "with open(os.path.join(save_path, \"settings.yaml\"), \"w\") as f:\n",
        "    yaml.dump(settings, f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QA from docs\n",
        "#### Map Reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "qa_chain = load_qa_chain(\n",
        "    llm = ChatOpenAI(temperature=0,\n",
        "                     model_name=\"gpt-4\",\n",
        "                     openai_api_key=OPENAI_KEY),\n",
        "    chain_type = \"map_reduce\",\n",
        "    verbose = True,\n",
        "    return_map_steps=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "86\n"
          ]
        }
      ],
      "source": [
        "documents = load_documents(os.path.join(DOCUMENT_SOURCE, PROJECT),\n",
        "                           exclude_pages=EXCLUDE_DICT)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=5000, chunk_overlap=500\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "print(len(texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combine_chain = \"\"\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qa_chain.run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37\n"
          ]
        }
      ],
      "source": [
        "documents = load_single_document(\n",
        "    os.path.join(MAIN_DIR, \"data/document_store/uc/juillerat 2022.pdf\")\n",
        ")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2500, chunk_overlap=500\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "print(len(texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2479"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[162], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m BULLET_POINT_PROMPT \u001b[39m=\u001b[39m PromptTemplate(template\u001b[39m=\u001b[39mprompt_template,\n\u001b[1;32m     14\u001b[0m                         input_variables\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m chain \u001b[39m=\u001b[39m load_summarize_chain(ChatOpenAI(model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                         openai_api_key\u001b[39m=\u001b[39mkeys[\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     18\u001b[0m                                         max_tokens\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                              map_prompt\u001b[39m=\u001b[39mBULLET_POINT_PROMPT\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m output_summary \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mrun(texts)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/base.py:236\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    130\u001b[0m     inputs,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/combine_documents/base.py:84\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m     83\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m---> 84\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m     85\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/combine_documents/map_reduce.py:144\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcombine_docs\u001b[39m(\n\u001b[1;32m    133\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    134\u001b[0m     docs: List[Document],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    138\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m    139\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \n\u001b[1;32m    141\u001b[0m \u001b[39m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    145\u001b[0m         \u001b[39m# FYI - this is parallelized and so it is fast.\u001b[39;49;00m\n\u001b[1;32m    146\u001b[0m         [{\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_variable_name: d\u001b[39m.\u001b[39;49mpage_content, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs} \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m docs],\n\u001b[1;32m    147\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_results(\n\u001b[1;32m    150\u001b[0m         results, docs, token_max, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    151\u001b[0m     )\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/llm.py:157\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    156\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    158\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)\n\u001b[1;32m    159\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end({\u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: outputs})\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/llm.py:154\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list, callbacks)\u001b[0m\n\u001b[1;32m    149\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    150\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    151\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39minput_list\u001b[39m\u001b[39m\"\u001b[39m: input_list},\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    155\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    156\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chains/llm.py:79\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m     80\u001b[0m     prompts, stop, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m     81\u001b[0m )\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chat_models/base.py:143\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    137\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    138\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m    139\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    142\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chat_models/base.py:91\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     92\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n\u001b[1;32m     93\u001b[0m generations \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results]\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chat_models/base.py:83\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks)\u001b[0m\n\u001b[1;32m     79\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[1;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m     84\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m     85\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     86\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m     87\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[1;32m     88\u001b[0m     ]\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chat_models/base.py:84\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[1;32m     80\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     85\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     86\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m     87\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[1;32m     88\u001b[0m     ]\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chat_models/openai.py:296\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager)\u001b[0m\n\u001b[1;32m    292\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[1;32m    293\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion, \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: role}\n\u001b[1;32m    294\u001b[0m     )\n\u001b[1;32m    295\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[0;32m--> 296\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chat_models/openai.py:257\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
            "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/langchain/chat_models/openai.py:255\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 255\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/openai/api_requestor.py:220\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[1;32m    223\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    224\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    225\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    226\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    227\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/openai/api_requestor.py:520\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[1;32m    519\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    521\u001b[0m         method,\n\u001b[1;32m    522\u001b[0m         abs_url,\n\u001b[1;32m    523\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    524\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    525\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    526\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    527\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    528\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    531\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
            "File \u001b[0;32m/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/urllib3/connection.py:454\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    453\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
            "File \u001b[0;32m/usr/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
            "File \u001b[0;32m/usr/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/usr/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "prompt_template = \"\"\"\n",
        "Write a summary on the following text:\n",
        "{text}\n",
        "\n",
        "The summary will contain information relevant to treatment for moderate to severe ulcerative colitis (UC) for\n",
        "the following patient profile: \n",
        "40 year old male with newly diagnosed moderate UC and articular extraintestinal manifestations\n",
        "\n",
        "The summary will contain the pros and cons of different biological drugs on the patient.\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "BULLET_POINT_PROMPT = PromptTemplate(template=prompt_template,\n",
        "                        input_variables=[\"text\"])\n",
        "\n",
        "chain = load_summarize_chain(ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
        "                                        openai_api_key=keys[\"OPENAI_API_KEY\"],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0), \n",
        "                             chain_type=\"map_reduce\", \n",
        "                             map_prompt=BULLET_POINT_PROMPT\n",
        ")\n",
        "\n",
        "output_summary = chain.run(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('The article discusses the efficacy and safety of different biological drugs '\n",
            " 'for the treatment of inflammatory bowel diseases (IBD), such as ulcerative '\n",
            " \"colitis (UC) and Crohn's disease (CD). The choice of drug should be based on \"\n",
            " 'individual patient factors such as disease severity, response to previous '\n",
            " 'treatments, and potential side effects. Anti-TNF agents, vedolizumab, '\n",
            " 'ustekinumab, etrolizumab, golimumab, and guselkumab are all potential '\n",
            " 'options for treatment. A personalized approach to treatment is recommended.')\n"
          ]
        }
      ],
      "source": [
        "pprint(output_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([text.page_content for text in texts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "367\n"
          ]
        }
      ],
      "source": [
        "# documents = load_documents(os.path.join(DOCUMENT_SOURCE, PROJECT),\n",
        "#                            exclude_pages=EXCLUDE_DICT)\n",
        "\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=1000, chunk_overlap=250\n",
        "# )\n",
        "# texts = text_splitter.split_documents(documents)\n",
        "# print(len(texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unstructured Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "('Stools (no./d) Formed stool <4 >6 >10 Blood in stools None Intermittent '\n",
            " 'Frequent Continuous Urgency None Mild, occasional Often Continuous '\n",
            " 'Hemoglobin Normal Normal pel ee ESR <30 <30 >30 >30 CRP (mg/L) Normal '\n",
            " 'Elevated Elevated Elevated FC (ug/g) < 150-200 > 150-200 > 150-200 > 150-200 '\n",
            " 'Endoscopy (Mayo subscore) 0-1 1 2-3 3 UCEIS 0-1 2-4 5-8 7-8')\n"
          ]
        }
      ],
      "source": [
        "sample_img = os.path.join(MAIN_DIR,\n",
        "                          \"data/tables/grading_disease_activity_agrawal.JPG\")\n",
        "loader = UnstructuredImageLoader(sample_img)\n",
        "data = loader.load()\n",
        "print(len(data))\n",
        "pprint(data[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Stools (no./d) Formed stool <4 >6 >10 Blood in stools None Intermittent Frequent Continuous Urgency None Mild, occasional Often Continuous Hemoglobin Normal Normal pel ee ESR <30 <30 >30 >30 CRP (mg/L) Normal Elevated Elevated Elevated FC (ug/g) < 150-200 > 150-200 > 150-200 > 150-200 Endoscopy (Mayo subscore) 0-1 1 2-3 3 UCEIS 0-1 2-4 5-8 7-8', metadata={'source': '/mnt/c/Users/QUAN/Desktop/medical-chatbot/data/tables/grading_disease_activity_agrawal.JPG'})]"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eZpX-1Ssy6Mw"
      },
      "source": [
        "## Custom Agent\n",
        "\n",
        "### QA from text Agent"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3msqfy9mzakH"
      },
      "source": [
        "### CSV Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXicAIYbzk8H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plu6jwcRX0yx"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "model_name = 'text-davinci-003'\n",
        "temperature = 0.0\n",
        "model = OpenAI(model_name=model_name, temperature=temperature, openai_api_key = OPENAI_KEY)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "joke_query = \"Tell me a joke.\"\n",
        "_input = prompt.format_prompt(query=joke_query)\n",
        "\n",
        "output = model(_input.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6kqb4R0bYwq",
        "outputId": "a4e2a631-50c6-4262-9493-0a16232b3765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer the user query.\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"drug_name\": {\"title\": \"Drug Name\", \"description\": \"Name of the drug\", \"type\": \"string\"}, \"description\": {\"title\": \"Description\", \"description\": \"Overall summary of the drug\", \"type\": \"string\"}, \"advantages\": {\"title\": \"Advantages\", \"description\": \"Advantages of the drug \", \"type\": \"string\"}, \"disadvantages\": {\"title\": \"Disadvantages\", \"description\": \"Disadvantages of the drug\", \"type\": \"string\"}}, \"required\": [\"drug_name\", \"description\", \"advantages\", \"disadvantages\"]}\n",
            "```\n",
            "Tell me a joke.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(_input.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gvu1sUauYISd",
        "outputId": "7e144f57-ef05-48f2-e1d3-393cba3d0fe3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n{\"drug_name\": \"Joke\", \"description\": \"A joke to make you laugh\", \"advantages\": \"It can make you laugh and bring joy\", \"disadvantages\": \"It may not be funny\"}'"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
