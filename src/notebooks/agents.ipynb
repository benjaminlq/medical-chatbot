{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/QUAN/Desktop/medical-chatbot/venv/lib/python3.8/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, json, logging\n",
    "import os.path as osp\n",
    "import re\n",
    "\n",
    "from typing import Any, Union, Tuple, Dict, Callable, List, Optional, Literal\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from langchain.docstore.document import Document\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import VectorStore, FAISS, Chroma, Pinecone\n",
    "import pinecone\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser, ListOutputParser\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.combine_documents.base import BaseCombineDocumentsChain\n",
    "from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain, _split_list_of_docs, _collapse_docs\n",
    "from langchain.chains.combine_documents.refine import RefineDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "from custom_parsers import DrugOutput, DrugParser\n",
    "\n",
    "import config\n",
    "from config import MAIN_DIR, DATA_DIR, ARTIFACT_DIR, DOCUMENT_SOURCE\n",
    "\n",
    "from shutil import rmtree\n",
    "from utils import load_single_document, load_documents, convert_json_to_documents, convert_csv_to_documents\n",
    "import yaml\n",
    "\n",
    "from pydantic import root_validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"uc\"\n",
    "\n",
    "with open(osp.join(MAIN_DIR, \"auth\", \"api_keys.json\"), \"r\") as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "OPENAI_KEY = keys[\"OPENAI_API_KEY\"]\n",
    "SOURCE_DATA = os.path.join(DOCUMENT_SOURCE, PROJECT)\n",
    "EMBSTORE_DIR = os.path.join(config.EMBSTORE_DIR, PROJECT, \"faiss\", \"text-embedding-ada-002\")\n",
    "\n",
    "EXCLUDE_DICT = {\n",
    "    \"agrawal.pdf\": [13, 14, 15, 16, 17, 18],\n",
    "    \"PIIS1542356520300446.pdf\": [12, 13, 14, 15, 16, 17, 18],\n",
    "    \"gutjnl-2021-326390R2 CLEAN.pdf\": [0, 2, 31, 32, 33, 34, 35, 36,\n",
    "                                       37, 38, 39, 40, 41, 42, 43, 44, 45]\\\n",
    "                                        + list(range(3, 31)),\n",
    "    \"otad009.pdf\": [15, 16],\n",
    "    \"1-s2.0-S2468125321003770-main.pdf\": [9],\n",
    "    \"juillerat 2022.pdf\": [6, 7, 8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger()\n",
    "\n",
    "log_path = os.path.join(MAIN_DIR, \"log\", \"logfile.txt\")\n",
    "file_handler = logging.FileHandler(\n",
    "    filename=log_path)\n",
    "\n",
    "formatter = logging.Formatter(\"%(asctime)s:%(levelname)s: %(message)s\")\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "LOGGER.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_documents(table_info: Dict, concatenate_rows: bool = True) -> List[Document]:\n",
    "    assert table_info[\"mode\"] == \"table\" and table_info[\"filename\"].endswith(\".csv\")\n",
    "    rows = load_single_document(os.path.join(MAIN_DIR, table_info[\"filename\"]))\n",
    "    documents = []\n",
    "    table_content = table_info[\"description\"] + \"\\n\\n\"\n",
    "    for row in rows:\n",
    "        if concatenate_rows:\n",
    "            table_content += row.page_content + \"\\n\\n\"\n",
    "            table_doc = Document(\n",
    "                page_content=table_content,\n",
    "                metadata=table_info[\"metadata\"]\n",
    "            )\n",
    "        else:\n",
    "            row_no = row.metadata[\"row\"]\n",
    "            metadata = {k: v for k, v in table_info[\"metadata\"].items()}\n",
    "            metadata[\"row\"] = row_no\n",
    "            metadata[\"modal\"] = table_info[\"mode\"]\n",
    "            row.page_content = table_info[\"description\"] + \":\" + row.page_content\n",
    "            row.metadata = metadata\n",
    "            documents.append(row)\n",
    "            \n",
    "    if concatenate_rows:\n",
    "        documents.append(table_doc)\n",
    "    \n",
    "    return documents\n",
    "    \n",
    "def check_documents_token(\n",
    "    docs: List[Document],\n",
    "    llm = ChatOpenAI(temperature=0,\n",
    "                     model_name=\"gpt-3.5-turbo\",\n",
    "                     openai_api_key=OPENAI_KEY)\n",
    "    ):\n",
    "    if not isinstance(docs, List):\n",
    "        docs = [docs]\n",
    "    combine_document_chain = StuffDocumentsChain(\n",
    "        llm_chain=LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=PromptTemplate(template=\"{summaries}\",\n",
    "                                input_variables=[\"summaries\"]),\n",
    "            verbose=False,\n",
    "        ),\n",
    "        verbose=False\n",
    "    )\n",
    "    return combine_document_chain.prompt_length(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapReduceDocumentsChainV2(MapReduceDocumentsChain):\n",
    "    combine_max_tokens: int = 30000\n",
    "    collapse_max_tokens: int = 5000\n",
    "\n",
    "    @root_validator()\n",
    "    def check_maximum_context_length(cls, values: Dict) -> Dict:\n",
    "        max_token_dict = {\n",
    "            \"gpt-3.5-turbo\": 3000,\n",
    "            \"gpt-3.5-turbo-16k\": 14000,\n",
    "            \"gpt-4\": 7000,\n",
    "            \"gpt-4-32k\": 30000\n",
    "        }\n",
    "        \n",
    "        combine_doc_llm_model = values[\"combine_document_chain\"].llm_chain.llm.model_name\n",
    "        if combine_doc_llm_model in max_token_dict:\n",
    "            if max_token_dict[combine_doc_llm_model] < values[\"combine_max_tokens\"]:\n",
    "                values[\"combine_max_tokens\"] = max_token_dict[combine_doc_llm_model]\n",
    "        \n",
    "        if values[\"collapse_document_chain\"]:\n",
    "            collapse_doc_llm_model = values[\"collapse_document_chain\"].llm_chain.llm.model_name\n",
    "        else:\n",
    "            collapse_doc_llm_model = values[\"combine_document_chain\"].llm_chain.llm.model_name\n",
    "        \n",
    "        if collapse_doc_llm_model in max_token_dict:\n",
    "            if max_token_dict[collapse_doc_llm_model] < values[\"collapse_max_tokens\"]:\n",
    "                values[\"collapse_max_tokens\"] = max_token_dict[collapse_doc_llm_model]\n",
    "\n",
    "        return values\n",
    "\n",
    "    def combine_docs(\n",
    "        self,\n",
    "        docs: List[Document],\n",
    "        callbacks: Callbacks = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Tuple[str, dict]:\n",
    "        \"\"\"Combine documents in a map reduce manner.\n",
    "\n",
    "        Combine by mapping first chain over all documents, then reducing the results.\n",
    "        This reducing can be done recursively if needed (if there are many documents).\n",
    "        \"\"\"\n",
    "        results = self.llm_chain.apply(\n",
    "            # FYI - this is parallelized and so it is fast.\n",
    "            [{self.document_variable_name: d.page_content, **kwargs} for d in docs],\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        return self._process_results(\n",
    "            results, docs, callbacks=callbacks, **kwargs\n",
    "        )\n",
    "\n",
    "    def _process_results(\n",
    "        self,\n",
    "        results: List[Dict],\n",
    "        docs: List[Document],\n",
    "        callbacks: Callbacks = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Tuple[str, dict]:\n",
    "        question_result_key = self.llm_chain.output_key\n",
    "        result_docs = [\n",
    "            Document(page_content=r[question_result_key], metadata=docs[i].metadata)\n",
    "            # This uses metadata from the docs, and the textual results from `results`\n",
    "            for i, r in enumerate(results)\n",
    "        ]\n",
    "        length_func = self.combine_document_chain.prompt_length\n",
    "        num_tokens = length_func(result_docs, **kwargs)\n",
    "\n",
    "        def _collapse_docs_func(docs: List[Document], **kwargs: Any) -> str:\n",
    "            return self._collapse_chain.run(\n",
    "                input_documents=docs, callbacks=callbacks, **kwargs\n",
    "            )\n",
    "\n",
    "        collapse_counter = 0\n",
    "        while num_tokens is not None and num_tokens > self.combine_max_tokens:\n",
    "            \n",
    "            # \n",
    "            collapse_counter += 1\n",
    "            if collapse_counter == 2:\n",
    "                raise Exception(\"Double Collapse steps. Stop\")            \n",
    "            \n",
    "            new_result_doc_list = _split_list_of_docs(\n",
    "                result_docs, length_func, self.collapse_max_tokens, **kwargs\n",
    "            )\n",
    "            result_docs = []\n",
    "            for docs in new_result_doc_list:\n",
    "                new_doc = _collapse_docs(docs, _collapse_docs_func, **kwargs)\n",
    "                result_docs.append(new_doc)\n",
    "            num_tokens = self.combine_document_chain.prompt_length(\n",
    "                result_docs, **kwargs\n",
    "            )\n",
    "        if self.return_intermediate_steps:\n",
    "            _results = [r[self.llm_chain.output_key] for r in results]\n",
    "            extra_return_dict = {\"intermediate_steps\": _results}\n",
    "        else:\n",
    "            extra_return_dict = {}\n",
    "        output = self.combine_document_chain.run(\n",
    "            input_documents=result_docs, callbacks=callbacks, **kwargs\n",
    "        )\n",
    "        return output, extra_return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['40 year old male with newly diagnosed moderate UC and articular extraintestinal manifestations',\n",
       " '70 year old female with newly diagnosed severe UC',\n",
       " '35 year old male with known moderate UC with prior exposure to infliximab but has worsening colitis on endoscopy despite compliance',\n",
       " '60 year old female with newly diagnosed moderate UC with a background of congestive cardiac failure',\n",
       " '38 year old female with newly diagnosed moderate UC and psoriasis',\n",
       " '25 year old pregnant woman with severe distal ulcerative colitis',\n",
       " '56 year old man with moderate to severe ulcerative colitis and ankylosing spondylitis',\n",
       " '38 year old man with severe ulcerative colitis and has lost response to vedolizumab',\n",
       " '28 year old woman who has severe extensive ulcerative colitis and has a history of lymphoma which was treated 4 years ago',\n",
       " '36 year old woman with moderate ulcerative colitis and multiple sclerosis']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(osp.join(DATA_DIR, \"queries\", \"uc.txt\"), \"r\", encoding = \"utf-8-sig\") as f:\n",
    "    test_cases = f.readlines()\n",
    "\n",
    "test_cases = [test_case.rstrip() for test_case in test_cases]\n",
    "test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import load_tools\n",
    "from langchain.tools.base import BaseTool\n",
    "\n",
    "from custom_chain import MapReduceDocumentsChainV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature = 0,\n",
    "    openai_api_key = OPENAI_KEY,\n",
    "    max_tokens = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieverTool(BaseTool):\n",
    "    description: \"Use this tool to search for information regarding treatment for patients with moderate to severe ulcerative colititis (UC)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
